============================= test session starts ==============================
platform darwin -- Python 3.11.13, pytest-9.0.1, pluggy-1.6.0 -- /Users/darianrosebrook/Desktop/Projects/distill/venv/bin/python3.11
cachedir: .pytest_cache
hypothesis profile 'default'
rootdir: /Users/darianrosebrook/Desktop/Projects/distill
configfile: pytest.ini
plugins: anyio-4.11.0, hypothesis-6.147.0, timeout-2.4.0, cov-7.0.0
timeout: 30.0s
timeout method: thread
timeout func_only: False
collecting ... collected 635 items

tests/evaluation/test_8ball_eval.py::TestEightBallConstants::test_eight_ball_answers_count PASSED [  0%]
tests/evaluation/test_8ball_eval.py::TestEightBallConstants::test_eight_ball_answers_content PASSED [  0%]
tests/evaluation/test_8ball_eval.py::TestEightBallConstants::test_eight_ball_token_ids_range PASSED [  0%]
tests/evaluation/test_8ball_eval.py::TestEightBallConstants::test_id_to_answer_mapping PASSED [  0%]
tests/evaluation/test_8ball_eval.py::TestEightBallConstants::test_id_to_answer_coverage PASSED [  0%]
tests/evaluation/test_8ball_eval.py::TestDataClasses::test_prediction_result_creation PASSED [  0%]
tests/evaluation/test_8ball_eval.py::TestDataClasses::test_evaluation_metrics_creation PASSED [  1%]
tests/evaluation/test_8ball_eval.py::TestLoadEvalQuestions::test_load_eval_questions_json_file PASSED [  1%]
tests/evaluation/test_8ball_eval.py::TestLoadEvalQuestions::test_load_eval_questions_text_file PASSED [  1%]
tests/evaluation/test_8ball_eval.py::TestLoadEvalQuestions::test_load_eval_questions_nonexistent_file PASSED [  1%]
tests/evaluation/test_8ball_eval.py::TestLoadEvalQuestions::test_load_eval_questions_invalid_json PASSED [  1%]
tests/evaluation/test_8ball_eval.py::TestEvaluatePyTorchModel::test_evaluate_pytorch_model_success PASSED [  1%]
tests/evaluation/test_8ball_eval.py::TestEvaluatePyTorchModel::test_evaluate_pytorch_model_empty_questions PASSED [  2%]
tests/evaluation/test_8ball_eval.py::TestEvaluatePyTorchModel::test_evaluate_pytorch_model_tokenizer_failure PASSED [  2%]
tests/evaluation/test_8ball_eval.py::TestEvaluatePyTorchModel::test_evaluate_pytorch_model_with_tokenizer_path PASSED [  2%]
tests/evaluation/test_8ball_eval.py::TestEvaluatePyTorchModel::test_evaluate_pytorch_model_import_error PASSED [  2%]
tests/evaluation/test_8ball_eval.py::TestEvaluatePyTorchModel::test_evaluate_pytorch_model_mock_path_handling PASSED [  2%]
tests/evaluation/test_8ball_eval.py::TestEvaluateCoreMLModel::test_evaluate_coreml_model_success PASSED [  2%]
tests/evaluation/test_8ball_eval.py::TestEvaluateCoreMLModel::test_evaluate_coreml_model_file_not_found PASSED [  2%]
tests/evaluation/test_8ball_eval.py::TestEvaluateCoreMLModel::test_evaluate_coreml_model_with_tokenizer_path PASSED [  3%]
tests/evaluation/test_8ball_eval.py::TestEvaluateCoreMLModel::test_evaluate_coreml_model_import_error PASSED [  3%]
tests/evaluation/test_8ball_eval.py::TestEvaluateCoreMLModel::test_evaluate_coreml_model_exception_handling PASSED [  3%]
tests/evaluation/test_8ball_eval.py::TestEvaluateOllamaModel::test_evaluate_ollama_model_success PASSED [  3%]
tests/evaluation/test_8ball_eval.py::TestEvaluateOllamaModel::test_evaluate_ollama_model_subprocess_failure PASSED [  3%]
tests/evaluation/test_8ball_eval.py::TestEvaluateOllamaModel::test_evaluate_ollama_model_invalid_json PASSED [  3%]
tests/evaluation/test_8ball_eval.py::TestEvaluateOllamaModel::test_evaluate_ollama_model_timeout PASSED [  4%]
tests/evaluation/test_8ball_eval.py::TestEvaluateOllamaModel::test_evaluate_ollama_model_json_with_response_key PASSED [  4%]
tests/evaluation/test_8ball_eval.py::TestEvaluateOllamaModel::test_evaluate_ollama_model_finds_token_in_output PASSED [  4%]
tests/evaluation/test_8ball_eval.py::TestEvaluateOllamaModel::test_evaluate_ollama_model_fallback_to_default_token PASSED [  4%]
tests/evaluation/test_8ball_eval.py::TestEvaluateOllamaModel::test_evaluate_ollama_model_empty_questions PASSED [  4%]
tests/evaluation/test_8ball_eval.py::TestComparePredictions::test_compare_predictions_identical PASSED [  4%]
tests/evaluation/test_8ball_eval.py::TestComparePredictions::test_compare_predictions_different PASSED [  5%]
tests/evaluation/test_8ball_eval.py::TestComparePredictions::test_compare_predictions_empty_lists PASSED [  5%]
tests/evaluation/test_8ball_eval.py::TestComparePredictions::test_compare_predictions_different_lengths PASSED [  5%]
tests/evaluation/test_8ball_eval.py::TestComparePredictions::test_compare_predictions_token_distribution PASSED [  5%]
tests/evaluation/test_8ball_eval.py::TestComparePredictions::test_compare_predictions_with_probabilities PASSED [  5%]
tests/evaluation/test_8ball_eval.py::TestComparePredictions::test_compare_predictions_probability_drift_different_predictions PASSED [  5%]
tests/evaluation/test_8ball_eval.py::TestComparePredictions::test_compare_predictions_without_probabilities PASSED [  5%]
tests/evaluation/test_8ball_eval.py::TestComparePredictions::test_compare_predictions_with_class_id_only PASSED [  6%]
tests/evaluation/test_8ball_eval.py::TestComparePredictions::test_compare_predictions_token_distribution_calculation PASSED [  6%]
tests/evaluation/test_8ball_eval.py::TestComparePredictions::test_compare_predictions_answer_distribution PASSED [  6%]
tests/evaluation/test_8ball_eval.py::TestComparePredictions::test_compare_predictions_token_out_of_range PASSED [  6%]
tests/evaluation/test_8ball_eval.py::TestMainFunction::test_main_pytorch_evaluation PASSED [  6%]
tests/evaluation/test_8ball_eval.py::TestMainFunction::test_main_coreml_evaluation PASSED [  6%]
tests/evaluation/test_8ball_eval.py::TestMainFunction::test_main_ollama_evaluation PASSED [  7%]
tests/evaluation/test_8ball_eval.py::TestMainFunction::test_main_invalid_backend PASSED [  7%]
tests/evaluation/test_8ball_eval.py::TestMainFunction::test_main_missing_eval_file PASSED [  7%]
tests/evaluation/test_8ball_eval.py::TestMainFunction::test_main_with_output_file PASSED [  7%]
tests/evaluation/test_8ball_eval.py::TestMainFunction::test_main_with_reference_comparison PASSED [  7%]
tests/evaluation/test_8ball_eval.py::TestMainFunction::test_main_load_questions_error PASSED [  7%]
tests/evaluation/test_8ball_eval.py::TestMainFunction::test_main_no_eval_file_specified PASSED [  8%]
tests/evaluation/test_8ball_eval.py::TestEightBallIntegration::test_eight_ball_answer_consistency PASSED [  8%]
tests/evaluation/test_8ball_eval.py::TestEightBallIntegration::test_prediction_result_validation PASSED [  8%]
tests/evaluation/test_8ball_eval.py::TestEightBallIntegration::test_evaluation_metrics_calculation PASSED [  8%]
tests/evaluation/test_8ball_eval.py::TestEightBallIntegration::test_evaluation_workflow PASSED [  8%]
tests/evaluation/test_8ball_eval.py::TestEightBallIntegration::test_prediction_result_post_init_with_class_id_only PASSED [  8%]
tests/evaluation/test_8ball_eval.py::TestEightBallIntegration::test_prediction_result_post_init_with_token_only PASSED [  8%]
tests/evaluation/test_8ball_eval.py::TestEightBallIntegration::test_prediction_result_post_init_invalid_token PASSED [  9%]
tests/evaluation/test_8ball_eval.py::TestEightBallIntegration::test_prediction_result_with_class_probabilities PASSED [  9%]
tests/evaluation/test_8ball_eval.py::TestEightBallIntegration::test_evaluation_metrics_post_init_with_legacy_fields PASSED [  9%]
tests/evaluation/test_8ball_eval.py::TestEightBallIntegration::test_evaluation_metrics_post_init_with_new_fields PASSED [  9%]
tests/evaluation/test_8ball_eval.py::TestEightBallIntegration::test_evaluation_metrics_post_init_calculated_accuracy PASSED [  9%]
tests/evaluation/test_8ball_eval.py::TestEightBallIntegration::test_evaluation_metrics_post_init_zero_questions PASSED [  9%]
tests/evaluation/test_8ball_eval.py::TestEightBallIntegration::test_load_eval_questions_list_input PASSED [ 10%]
tests/evaluation/test_8ball_eval.py::TestEightBallIntegration::test_load_eval_questions_dict_with_questions_key PASSED [ 10%]
tests/evaluation/test_8ball_eval.py::TestEightBallIntegration::test_load_eval_questions_json_decode_error_on_json_file PASSED [ 10%]
tests/evaluation/test_8ball_eval.py::TestEightBallIntegration::test_load_eval_questions_text_file_with_empty_lines PASSED [ 10%]
tests/evaluation/test_8ball_eval.py::TestEightBallIntegration::test_load_eval_questions_invalid_type PASSED [ 10%]
tests/evaluation/test_8ball_eval.py::TestEightBallIntegration::test_load_eval_questions_value_error_fallback PASSED [ 10%]
tests/evaluation/test_8ball_eval.py::TestEvaluatePyTorchModelEdgeCases::test_evaluate_pytorch_model_missing_questions_argument PASSED [ 11%]
tests/evaluation/test_8ball_eval.py::TestEvaluateCoreMLModelEdgeCases::test_evaluate_coreml_model_missing_questions_argument PASSED [ 11%]
tests/evaluation/test_8ball_eval.py::TestComparePredictionsEdgeCases::test_compare_predictions_empty_lists_detailed PASSED [ 11%]
tests/evaluation/test_8ball_eval.py::TestComparePredictionsEdgeCases::test_compare_predictions_token_index_bounds PASSED [ 11%]
tests/evaluation/test_8ball_eval.py::TestComparePredictionsEdgeCases::test_compare_predictions_with_none_answer PASSED [ 11%]
tests/evaluation/test_caws_eval.py::TestValidateBudgetAdherence::test_validate_budget_adherence_within_limits PASSED [ 11%]
tests/evaluation/test_caws_eval.py::TestValidateBudgetAdherence::test_validate_budget_adherence_exceeds_loc_limit PASSED [ 11%]
tests/evaluation/test_caws_eval.py::TestValidateBudgetAdherence::test_validate_budget_adherence_exceeds_files_limit PASSED [ 12%]
tests/evaluation/test_caws_eval.py::TestValidateBudgetAdherence::test_validate_budget_adherence_empty_diff PASSED [ 12%]
tests/evaluation/test_caws_eval.py::TestValidateBudgetAdherence::test_validate_budget_adherence_multiple_files PASSED [ 12%]
tests/evaluation/test_caws_eval.py::TestValidateBudgetAdherence::test_validate_budget_adherence_binary_files PASSED [ 12%]
tests/evaluation/test_caws_eval.py::TestValidateBudgetAdherence::test_validate_budget_adherence_edge_cases PASSED [ 12%]
tests/evaluation/test_caws_eval.py::TestValidateGateIntegrity::test_validate_gate_integrity_all_pass PASSED [ 12%]
tests/evaluation/test_caws_eval.py::TestValidateGateIntegrity::test_validate_gate_integrity_tests_fail PASSED [ 13%]
tests/evaluation/test_caws_eval.py::TestValidateGateIntegrity::test_validate_gate_integrity_lint_fail PASSED [ 13%]
tests/evaluation/test_caws_eval.py::TestValidateGateIntegrity::test_validate_gate_integrity_coverage_fail PASSED [ 13%]
tests/evaluation/test_caws_eval.py::TestValidateGateIntegrity::test_validate_gate_integrity_missing_fields PASSED [ 13%]
tests/evaluation/test_caws_eval.py::TestValidateProvenanceClarity::test_validate_provenance_clarity_complete PASSED [ 13%]
tests/evaluation/test_caws_eval.py::TestValidateProvenanceClarity::test_validate_provenance_clarity_missing_rationale PASSED [ 13%]
tests/evaluation/test_caws_eval.py::TestValidateProvenanceClarity::test_validate_provenance_clarity_missing_evidence PASSED [ 14%]
tests/evaluation/test_caws_eval.py::TestValidateProvenanceClarity::test_validate_provenance_clarity_no_diff PASSED [ 14%]
tests/evaluation/test_caws_eval.py::TestValidateProvenanceClarity::test_validate_provenance_clarity_whitespace_only PASSED [ 14%]
tests/evaluation/test_caws_eval.py::TestEvaluateCawsCompliance::test_evaluate_caws_compliance_all_pass PASSED [ 14%]
tests/evaluation/test_caws_eval.py::TestEvaluateCawsCompliance::test_evaluate_caws_compliance_gates_fail PASSED [ 14%]
tests/evaluation/test_caws_eval.py::TestEvaluateCawsCompliance::test_evaluate_caws_compliance_provenance_fail PASSED [ 14%]
tests/evaluation/test_caws_eval.py::TestEvaluateCawsCompliance::test_evaluate_caws_compliance_budget_fail PASSED [ 14%]
tests/evaluation/test_caws_eval.py::TestEvaluateCawsCompliance::test_evaluate_caws_compliance_multiple_failures PASSED [ 15%]
tests/evaluation/test_caws_eval.py::TestHelperFunctions::test_load_working_spec_success PASSED [ 15%]
tests/evaluation/test_caws_eval.py::TestHelperFunctions::test_load_working_spec_not_found PASSED [ 15%]
tests/evaluation/test_caws_eval.py::TestHelperFunctions::test_load_file_content_success PASSED [ 15%]
tests/evaluation/test_caws_eval.py::TestHelperFunctions::test_load_file_content_not_found PASSED [ 15%]
tests/evaluation/test_caws_eval.py::TestHelperFunctions::test_load_json_file_success PASSED [ 15%]
tests/evaluation/test_caws_eval.py::TestHelperFunctions::test_load_json_file_invalid_json PASSED [ 16%]
tests/evaluation/test_caws_eval.py::TestHelperFunctions::test_run_tests_success PASSED [ 16%]
tests/evaluation/test_caws_eval.py::TestHelperFunctions::test_run_tests_failure PASSED [ 16%]
tests/evaluation/test_caws_eval.py::TestHelperFunctions::test_run_linter_success PASSED [ 16%]
tests/evaluation/test_caws_eval.py::TestHelperFunctions::test_run_coverage_success PASSED [ 16%]
tests/evaluation/test_caws_eval.py::TestHelperFunctions::test_run_tests_timeout PASSED [ 16%]
tests/evaluation/test_caws_eval.py::TestHelperFunctions::test_run_tests_file_not_found PASSED [ 17%]
tests/evaluation/test_caws_eval.py::TestHelperFunctions::test_run_tests_text_parsing PASSED [ 17%]
tests/evaluation/test_caws_eval.py::TestHelperFunctions::test_run_linter_timeout PASSED [ 17%]
tests/evaluation/test_caws_eval.py::TestHelperFunctions::test_run_linter_no_linter_found PASSED [ 17%]
tests/evaluation/test_caws_eval.py::TestHelperFunctions::test_run_linter_text_parsing PASSED [ 17%]
tests/evaluation/test_caws_eval.py::TestHelperFunctions::test_run_coverage_timeout PASSED [ 17%]
tests/evaluation/test_caws_eval.py::TestHelperFunctions::test_run_coverage_file_not_found PASSED [ 17%]
tests/evaluation/test_caws_eval.py::TestHelperFunctions::test_run_coverage_json_file_parsing PASSED [ 18%]
tests/evaluation/test_caws_eval.py::TestHelperFunctions::test_load_file_content_empty_path PASSED [ 18%]
tests/evaluation/test_caws_eval.py::TestHelperFunctions::test_load_file_content_invalid_path PASSED [ 18%]
tests/evaluation/test_caws_eval.py::TestHelperFunctions::test_load_json_file_empty_path PASSED [ 18%]
tests/evaluation/test_caws_eval.py::TestHelperFunctions::test_load_json_file_invalid_path PASSED [ 18%]
tests/evaluation/test_caws_eval.py::TestHelperFunctions::test_evaluate_caws_compliance_with_evidence_string PASSED [ 18%]
tests/evaluation/test_caws_eval.py::TestHelperFunctions::test_evaluate_caws_compliance_with_evidence_json_string PASSED [ 19%]
tests/evaluation/test_caws_eval.py::TestHelperFunctions::test_evaluate_caws_compliance_with_diff_present PASSED [ 19%]
tests/evaluation/test_caws_eval.py::TestMainFunction::test_main_success PASSED [ 19%]
tests/evaluation/test_caws_eval.py::TestMainFunction::test_main_missing_spec PASSED [ 19%]
tests/evaluation/test_caws_eval.py::TestMainFunction::test_main_test_failure PASSED [ 19%]
tests/evaluation/test_caws_eval.py::TestCawsEvalIntegration::test_complete_caws_evaluation_workflow PASSED [ 19%]
tests/evaluation/test_caws_eval.py::TestCawsEvalIntegration::test_caws_evaluation_with_violations PASSED [ 20%]
tests/evaluation/test_caws_eval.py::TestCawsEvalIntegration::test_budget_adherence_edge_cases PASSED [ 20%]
tests/evaluation/test_caws_eval.py::TestCawsEvalIntegration::test_gate_integrity_thresholds PASSED [ 20%]
tests/evaluation/test_caws_eval.py::TestCawsEvalIntegration::test_provenance_clarity_validation PASSED [ 20%]
tests/evaluation/test_caws_eval.py::TestCawsEvalIntegration::test_validate_budget_adherence_inferred_removals_special_case PASSED [ 20%]
tests/evaluation/test_caws_eval.py::TestCawsEvalIntegration::test_validate_budget_adherence_inferred_additions_special_case PASSED [ 20%]
tests/evaluation/test_caws_eval.py::TestCawsEvalIntegration::test_validate_budget_adherence_net_change_mismatch PASSED [ 20%]
tests/evaluation/test_caws_eval.py::TestCawsEvalIntegration::test_validate_budget_adherence_multiple_hunks PASSED [ 21%]
tests/evaluation/test_caws_eval.py::TestCawsEvalIntegration::test_validate_budget_adherence_file_path_extraction PASSED [ 21%]
tests/evaluation/test_caws_eval.py::TestCawsEvalIntegration::test_validate_budget_adherence_dev_null_ignored PASSED [ 21%]
tests/evaluation/test_caws_eval.py::TestCawsEvalIntegration::test_validate_gate_integrity_all_passed_field PASSED [ 21%]
tests/evaluation/test_caws_eval.py::TestCawsEvalIntegration::test_validate_gate_integrity_custom_coverage_threshold PASSED [ 21%]
tests/evaluation/test_caws_eval.py::TestCawsEvalIntegration::test_validate_gate_integrity_no_passed_tests PASSED [ 21%]
tests/evaluation/test_caws_eval.py::TestCawsEvalIntegration::test_validate_provenance_clarity_none_values PASSED [ 22%]
tests/evaluation/test_caws_eval.py::TestCawsEvalIntegration::test_validate_provenance_clarity_long_inputs PASSED [ 22%]
tests/evaluation/test_caws_eval.py::TestCawsEvalIntegration::test_evaluate_caws_compliance_partial_failure PASSED [ 22%]
tests/evaluation/test_caws_eval.py::TestCawsEvalIntegration::test_run_tests_invalid_json PASSED [ 22%]
tests/evaluation/test_caws_eval.py::TestCawsEvalIntegration::test_run_linter_exception PASSED [ 22%]
tests/evaluation/test_caws_eval.py::TestCawsEvalIntegration::test_run_coverage_no_output PASSED [ 22%]
tests/evaluation/test_caws_eval.py::TestCawsEvalIntegration::test_load_json_file_not_found PASSED [ 22%]
tests/evaluation/test_caws_eval.py::TestCawsEvalIntegration::test_load_file_content_empty_file PASSED [ 23%]
tests/evaluation/test_caws_eval.py::TestCawsEvalIntegration::test_load_working_spec_yaml_error PASSED [ 23%]
tests/evaluation/test_claim_extraction_metrics.py::TestClaimExtractionEvalResult::test_claim_extraction_eval_result_creation PASSED [ 23%]
tests/evaluation/test_claim_extraction_metrics.py::TestClaimExtractionEvalResult::test_claim_extraction_eval_result_default_values PASSED [ 23%]
tests/evaluation/test_claim_extraction_metrics.py::TestClaimExtractionEvalResult::test_claim_extraction_eval_result_calculated_fields PASSED [ 23%]
tests/evaluation/test_claim_extraction_metrics.py::TestClaimExtractionEvaluator::test_evaluator_initialization_with_extractor PASSED [ 23%]
tests/evaluation/test_claim_extraction_metrics.py::TestClaimExtractionEvaluator::test_evaluator_initialization_default PASSED [ 24%]
tests/evaluation/test_claim_extraction_metrics.py::TestClaimExtractionEvaluator::test_evaluate_success PASSED [ 24%]
tests/evaluation/test_claim_extraction_metrics.py::TestClaimExtractionEvaluator::test_evaluate_empty_outputs PASSED [ 24%]
tests/evaluation/test_claim_extraction_metrics.py::TestClaimExtractionEvaluator::test_evaluate_single_output PASSED [ 24%]
tests/evaluation/test_claim_extraction_metrics.py::TestClaimExtractionEvaluator::test_evaluate_mismatched_lengths PASSED [ 24%]
tests/evaluation/test_claim_extraction_metrics.py::TestClaimExtractionEvaluator::test_evaluate_with_none_outputs PASSED [ 24%]
tests/evaluation/test_claim_extraction_metrics.py::TestClaimExtractionEvaluator::test_evaluate_extractor_failure PASSED [ 25%]
tests/evaluation/test_claim_extraction_metrics.py::TestClaimExtractionMetricsIntegration::test_complete_evaluation_workflow PASSED [ 25%]
tests/evaluation/test_claim_extraction_metrics.py::TestClaimExtractionMetricsIntegration::test_evaluation_with_realistic_outputs PASSED [ 25%]
tests/evaluation/test_claim_extraction_metrics.py::TestClaimExtractionMetricsIntegration::test_metrics_calculation_edge_cases PASSED [ 25%]
tests/evaluation/test_claim_extraction_metrics.py::TestClaimExtractionMetricsIntegration::test_evaluator_reuse PASSED [ 25%]
tests/evaluation/test_claim_extraction_metrics.py::TestClaimExtractionMetricsIntegration::test_evaluator_with_different_extractors PASSED [ 25%]
tests/evaluation/test_claim_extraction_metrics.py::TestFormatResults::test_format_results_basic PASSED [ 25%]
tests/evaluation/test_claim_extraction_metrics.py::TestFormatResults::test_format_results_zero_values PASSED [ 26%]
tests/evaluation/test_claim_extraction_metrics.py::TestEvaluateFromDataset::test_evaluate_from_dataset_basic PASSED [ 26%]
tests/evaluation/test_claim_extraction_metrics.py::TestEvaluateFromDataset::test_evaluate_from_dataset_with_max_samples PASSED [ 26%]
tests/evaluation/test_claim_extraction_metrics.py::TestRealClaimExtraction::test_evaluator_with_real_extractor PASSED [ 26%]
tests/evaluation/test_claim_extraction_metrics.py::TestRealClaimExtraction::test_evaluator_with_real_extractor_verifiable_content PASSED [ 26%]
tests/evaluation/test_claim_extraction_metrics.py::TestRealClaimExtraction::test_evaluator_with_real_extractor_unverifiable_content PASSED [ 26%]
tests/evaluation/test_claim_extraction_metrics.py::TestRealClaimExtraction::test_evaluator_with_real_extractor_empty_text PASSED [ 27%]
tests/evaluation/test_claim_extraction_metrics.py::TestRealClaimExtraction::test_evaluator_with_real_extractor_code_blocks PASSED [ 27%]
tests/evaluation/test_claim_extraction_metrics.py::TestRealClaimExtraction::test_evaluator_with_real_extractor_json_content PASSED [ 27%]
tests/evaluation/test_claim_extraction_metrics.py::TestRealClaimExtraction::test_evaluator_with_real_extractor_urls PASSED [ 27%]
tests/evaluation/test_claim_extraction_metrics.py::TestRealClaimExtraction::test_evaluator_with_real_extractor_dates PASSED [ 27%]
tests/evaluation/test_claim_extraction_metrics.py::TestRealClaimExtraction::test_evaluator_loss_calculation_with_real_extractor PASSED [ 27%]
tests/evaluation/test_claim_extraction_metrics.py::TestComputeClaimExtractionMetricsReal::test_compute_claim_extraction_metrics_real_extractor PASSED [ 28%]
tests/evaluation/test_claim_extraction_metrics.py::TestComputeClaimExtractionMetricsReal::test_compute_claim_extraction_metrics_empty_text PASSED [ 28%]
tests/evaluation/test_claim_extraction_metrics.py::TestComputeClaimExtractionMetricsReal::test_compute_claim_extraction_metrics_none_extractor PASSED [ 28%]
tests/evaluation/test_claim_extraction_metrics.py::TestFormatResultsReal::test_format_results_real_data PASSED [ 28%]
tests/evaluation/test_claim_extraction_metrics.py::TestFormatResultsReal::test_format_results_zero_values PASSED [ 28%]
tests/evaluation/test_claim_extraction_metrics.py::TestFormatResultsReal::test_format_results_high_values PASSED [ 28%]
tests/evaluation/test_claim_extraction_metrics.py::TestEdgeCasesReal::test_evaluator_with_special_characters PASSED [ 28%]
tests/evaluation/test_claim_extraction_metrics.py::TestEdgeCasesReal::test_evaluator_with_unicode PASSED [ 29%]
tests/evaluation/test_claim_extraction_metrics.py::TestEdgeCasesReal::test_evaluator_with_newlines PASSED [ 29%]
tests/evaluation/test_claim_extraction_metrics.py::TestEdgeCasesReal::test_evaluator_ratio_calculation_edge_cases PASSED [ 29%]
tests/evaluation/test_claim_extraction_metrics.py::TestEdgeCasesReal::test_evaluator_with_multiple_samples_real PASSED [ 29%]
tests/evaluation/test_claim_extraction_metrics.py::TestEdgeCasesReal::test_evaluator_loss_thresholds PASSED [ 29%]
tests/evaluation/test_claim_extraction_metrics.py::TestEdgeCasesReal::test_evaluator_ratio_rounding PASSED [ 29%]
tests/evaluation/test_claim_extraction_metrics.py::TestEdgeCasesReal::test_evaluator_averaging_behavior PASSED [ 30%]
tests/evaluation/test_claim_extraction_metrics.py::TestEdgeCasesReal::test_evaluator_zero_teacher_claims PASSED [ 30%]
tests/evaluation/test_claim_extraction_metrics.py::TestEdgeCasesReal::test_evaluator_zero_student_claims PASSED [ 30%]
tests/evaluation/test_claim_extraction_metrics.py::TestEdgeCasesReal::test_evaluator_both_zero_claims PASSED [ 30%]
tests/evaluation/test_claim_extraction_metrics.py::TestEdgeCasesReal::test_evaluator_loss_penalty_calculation PASSED [ 30%]
tests/evaluation/test_claim_extraction_metrics.py::TestEdgeCasesReal::test_evaluator_single_sample PASSED [ 30%]
tests/evaluation/test_claim_extraction_metrics.py::TestEdgeCasesReal::test_evaluator_large_batch PASSED [ 31%]
tests/evaluation/test_claim_extraction_metrics.py::TestEdgeCasesReal::test_evaluator_default_extractor_creation PASSED [ 31%]
tests/evaluation/test_claim_extraction_metrics.py::TestEdgeCasesReal::test_evaluator_custom_extractor PASSED [ 31%]
tests/evaluation/test_claim_extraction_metrics.py::TestEdgeCasesReal::test_evaluator_min_thresholds_parameters PASSED [ 31%]
tests/evaluation/test_claim_extraction_metrics.py::TestEvaluateFromDatasetReal::test_evaluate_from_dataset_basic_flow PASSED [ 31%]
tests/evaluation/test_claim_extraction_metrics.py::TestEvaluateFromDatasetReal::test_evaluate_from_dataset_max_samples PASSED [ 31%]
tests/evaluation/test_claim_extraction_metrics.py::TestEvaluateFromDatasetReal::test_evaluate_from_dataset_empty_dataset PASSED [ 31%]
tests/evaluation/test_claim_extraction_metrics.py::TestEvaluateFromDatasetReal::test_evaluate_from_dataset_list_teacher_text PASSED [ 32%]
tests/evaluation/test_claim_extraction_metrics.py::TestEvaluateFromDatasetReal::test_evaluate_from_dataset_empty_list_teacher_text PASSED [ 32%]
tests/evaluation/test_claim_extraction_metrics.py::TestEvaluateFromDatasetReal::test_evaluate_from_dataset_missing_teacher_text PASSED [ 32%]
tests/evaluation/test_claim_extraction_metrics.py::TestEvaluateFromDatasetReal::test_evaluate_from_dataset_missing_attention_mask PASSED [ 32%]
tests/evaluation/test_claim_extraction_metrics.py::TestEvaluateFromDatasetReal::test_evaluate_from_dataset_max_samples_exceeds_dataset_size PASSED [ 32%]
tests/evaluation/test_claim_extraction_metrics.py::TestLossCalculationEdgeCases::test_loss_calculation_zero_ratios PASSED [ 32%]
tests/evaluation/test_claim_extraction_metrics.py::TestLossCalculationEdgeCases::test_loss_calculation_meets_thresholds PASSED [ 33%]
tests/evaluation/test_claim_extraction_metrics.py::TestLossCalculationEdgeCases::test_loss_calculation_below_thresholds PASSED [ 33%]
tests/evaluation/test_claim_extraction_metrics.py::TestLossCalculationEdgeCases::test_loss_calculation_penalty_weights PASSED [ 33%]
tests/evaluation/test_claim_extraction_metrics.py::TestLossCalculationEdgeCases::test_loss_calculation_boundary_values PASSED [ 33%]
tests/evaluation/test_claim_extraction_metrics.py::TestClaimExtractionEvaluatorInitialization::test_evaluator_init_none_extractor PASSED [ 33%]
tests/evaluation/test_claim_extraction_metrics.py::TestClaimExtractionEvaluatorInitialization::test_evaluator_init_default_extractor PASSED [ 33%]
tests/evaluation/test_claim_extraction_metrics.py::TestClaimExtractionEvaluatorInitialization::test_evaluator_init_custom_extractor PASSED [ 34%]
tests/evaluation/test_claim_extraction_metrics.py::TestClaimExtractionEvalResultEdgeCases::test_eval_result_negative_values PASSED [ 34%]
tests/evaluation/test_claim_extraction_metrics.py::TestClaimExtractionEvalResultEdgeCases::test_eval_result_high_values PASSED [ 34%]
tests/evaluation/test_claim_extraction_metrics.py::TestClaimExtractionEvalResultEdgeCases::test_eval_result_fractional_counts PASSED [ 34%]
tests/evaluation/test_classification_eval.py::TestClassificationConfig::test_classification_config_creation PASSED [ 34%]
tests/evaluation/test_classification_eval.py::TestClassificationConfig::test_classification_config_validation PASSED [ 34%]
tests/evaluation/test_classification_eval.py::TestPredictionResult::test_prediction_result_creation PASSED [ 34%]
tests/evaluation/test_classification_eval.py::TestPredictionResult::test_prediction_result_without_probabilities PASSED [ 35%]
tests/evaluation/test_classification_eval.py::TestEvaluationMetrics::test_evaluation_metrics_creation PASSED [ 35%]
tests/evaluation/test_classification_eval.py::TestEvaluationMetrics::test_evaluation_metrics_minimal PASSED [ 35%]
tests/evaluation/test_classification_eval.py::TestLoadClassificationConfig::test_load_classification_config_success PASSED [ 35%]
tests/evaluation/test_classification_eval.py::TestLoadClassificationConfig::test_load_classification_config_file_not_found PASSED [ 35%]
tests/evaluation/test_classification_eval.py::TestLoadClassificationConfig::test_load_classification_config_invalid_json PASSED [ 35%]
tests/evaluation/test_classification_eval.py::TestLoadClassificationConfig::test_load_classification_config_missing_fields PASSED [ 36%]
tests/evaluation/test_classification_eval.py::TestEvaluatePyTorchModel::test_evaluate_pytorch_model_success PASSED [ 36%]
tests/evaluation/test_classification_eval.py::TestEvaluatePyTorchModel::test_evaluate_pytorch_model_empty_questions PASSED [ 36%]
tests/evaluation/test_classification_eval.py::TestEvaluatePyTorchModel::test_evaluate_pytorch_model_tokenizer_failure PASSED [ 36%]
tests/evaluation/test_classification_eval.py::TestEvaluateCoreMLModel::test_evaluate_coreml_model_success PASSED [ 36%]
tests/evaluation/test_classification_eval.py::TestEvaluateCoreMLModel::test_evaluate_coreml_model_file_not_found PASSED [ 36%]
tests/evaluation/test_classification_eval.py::TestEvaluateOllamaModel::test_evaluate_ollama_model_success PASSED [ 37%]
tests/evaluation/test_classification_eval.py::TestEvaluateOllamaModel::test_evaluate_ollama_model_subprocess_failure PASSED [ 37%]
tests/evaluation/test_classification_eval.py::TestEvaluateOllamaModel::test_evaluate_ollama_model_invalid_json PASSED [ 37%]
tests/evaluation/test_classification_eval.py::TestComparePredictions::test_compare_predictions_identical PASSED [ 37%]
tests/evaluation/test_classification_eval.py::TestComparePredictions::test_compare_predictions_different PASSED [ 37%]
tests/evaluation/test_classification_eval.py::TestComparePredictions::test_compare_predictions_empty_lists PASSED [ 37%]
tests/evaluation/test_classification_eval.py::TestComparePredictions::test_compare_predictions_different_lengths PASSED [ 37%]
tests/evaluation/test_classification_eval.py::TestComparePredictions::test_compare_predictions_with_probabilities PASSED [ 38%]
tests/evaluation/test_classification_eval.py::TestComparePredictions::test_compare_predictions_without_probabilities PASSED [ 38%]
tests/evaluation/test_classification_eval.py::TestMainFunction::test_main_pytorch_evaluation PASSED [ 38%]
tests/evaluation/test_classification_eval.py::TestMainFunction::test_main_coreml_evaluation PASSED [ 38%]
tests/evaluation/test_classification_eval.py::TestMainFunction::test_main_invalid_backend PASSED [ 38%]
tests/evaluation/test_classification_eval.py::TestMainFunction::test_main_config_not_found PASSED [ 38%]
tests/evaluation/test_classification_eval.py::TestClassificationEvalIntegration::test_complete_evaluation_workflow PASSED [ 39%]
tests/evaluation/test_classification_eval.py::TestClassificationEvalIntegration::test_evaluation_metrics_calculation PASSED [ 39%]
tests/evaluation/test_classification_eval.py::TestClassificationEvalIntegration::test_config_validation PASSED [ 39%]
tests/evaluation/test_classification_eval.py::TestClassificationEvalIntegration::test_prediction_result_validation PASSED [ 39%]
tests/evaluation/test_classification_eval.py::TestClassificationEvalIntegration::test_load_classification_config_module_path PASSED [ 39%]
tests/evaluation/test_classification_eval.py::TestClassificationEvalIntegration::test_load_classification_config_invalid_module_path PASSED [ 39%]
tests/evaluation/test_classification_eval.py::TestClassificationEvalIntegration::test_load_classification_config_module_not_found PASSED [ 40%]
tests/evaluation/test_classification_eval.py::TestClassificationEvalIntegration::test_load_classification_config_yaml_file PASSED [ 40%]
tests/evaluation/test_classification_eval.py::TestClassificationEvalIntegration::test_load_classification_config_yaml_not_installed PASSED [ 40%]
tests/evaluation/test_classification_eval.py::TestClassificationEvalIntegration::test_evaluate_pytorch_model_with_tokenizer_path PASSED [ 40%]
tests/evaluation/test_classification_eval.py::TestClassificationEvalIntegration::test_evaluate_pytorch_model_model_load_failure PASSED [ 40%]
tests/evaluation/test_classification_eval.py::TestClassificationEvalIntegration::test_evaluate_coreml_model_tokenizer_load_failure PASSED [ 40%]
tests/evaluation/test_classification_eval.py::TestClassificationEvalIntegration::test_evaluate_coreml_model_exception_handling PASSED [ 40%]
tests/evaluation/test_classification_eval.py::TestClassificationEvalIntegration::test_evaluate_ollama_model_empty_questions PASSED [ 41%]
tests/evaluation/test_classification_eval.py::TestClassificationEvalIntegration::test_evaluate_ollama_model_timeout PASSED [ 41%]
tests/evaluation/test_classification_eval.py::TestClassificationEvalIntegration::test_compare_predictions_kl_divergence PASSED [ 41%]
tests/evaluation/test_classification_eval.py::TestClassificationEvalIntegration::test_compare_predictions_per_class_accuracy PASSED [ 41%]
tests/evaluation/test_classification_eval.py::TestClassificationEvalIntegration::test_compare_predictions_prediction_confidence PASSED [ 41%]
tests/evaluation/test_classification_eval.py::TestLoadClassificationConfigEdgeCases::test_load_classification_config_empty_path PASSED [ 41%]
tests/evaluation/test_classification_eval.py::TestLoadClassificationConfigEdgeCases::test_load_classification_config_invalid_module_path_format PASSED [ 42%]
tests/evaluation/test_classification_eval.py::TestLoadClassificationConfigEdgeCases::test_load_classification_config_module_not_found_import_error PASSED [ 42%]
tests/evaluation/test_classification_eval.py::TestEvaluatePyTorchModelEdgeCases::test_evaluate_pytorch_model_missing_config_argument PASSED [ 42%]
tests/evaluation/test_classification_eval.py::TestEvaluatePyTorchModelEdgeCases::test_evaluate_pytorch_model_missing_config_with_tokenizer PASSED [ 42%]
tests/evaluation/test_classification_eval.py::TestEvaluatePyTorchModelEdgeCases::test_evaluate_pytorch_model_empty_questions_returns_empty PASSED [ 42%]
tests/evaluation/test_classification_eval.py::TestEvaluateCoreMLModelEdgeCases::test_evaluate_coreml_model_missing_config_argument PASSED [ 42%]
tests/evaluation/test_classification_eval.py::TestEvaluateCoreMLModelEdgeCases::test_evaluate_coreml_model_empty_questions_returns_empty PASSED [ 42%]
tests/evaluation/test_classification_eval.py::TestComparePredictionsEdgeCases::test_compare_predictions_empty_lists_detailed PASSED [ 43%]
tests/evaluation/test_classification_eval.py::TestComparePredictionsEdgeCases::test_classification_config_inconsistent_mappings PASSED [ 43%]
tests/evaluation/test_classification_eval.py::TestComparePredictionsEdgeCases::test_main_with_reference_comparison PASSED [ 43%]
tests/evaluation/test_classification_eval.py::TestComparePredictionsEdgeCases::test_main_load_config_error PASSED [ 43%]
tests/evaluation/test_classification_eval.py::TestComparePredictionsEdgeCases::test_prediction_result_probabilities_normalization PASSED [ 43%]
tests/evaluation/test_classification_eval.py::TestComparePredictionsEdgeCases::test_evaluation_metrics_all_fields PASSED [ 43%]
tests/evaluation/test_compare_8ball_pipelines.py::TestLoadEvalQuestions::test_load_eval_questions_from_json_file PASSED [ 44%]
tests/evaluation/test_compare_8ball_pipelines.py::TestLoadEvalQuestions::test_load_eval_questions_from_list_json PASSED [ 44%]
tests/evaluation/test_compare_8ball_pipelines.py::TestMainFunction::test_main_with_pytorch_only PASSED [ 44%]
tests/evaluation/test_compare_8ball_pipelines.py::TestMainFunction::test_main_with_pytorch_and_coreml PASSED [ 44%]
tests/evaluation/test_compare_8ball_pipelines.py::TestMainFunction::test_main_with_pytorch_and_ollama PASSED [ 44%]
tests/evaluation/test_compare_8ball_pipelines.py::TestMainFunction::test_main_with_temp_output_dir PASSED [ 44%]
tests/evaluation/test_compare_8ball_pipelines.py::TestMainFunction::test_main_saves_pytorch_predictions PASSED [ 45%]
tests/evaluation/test_compare_8ball_pipelines.py::TestMainFunction::test_main_saves_comparison_metrics PASSED [ 45%]
tests/evaluation/test_compare_8ball_pipelines.py::TestOutputDirectoryHandling::test_main_creates_temp_dir_when_not_provided PASSED [ 45%]
tests/evaluation/test_compare_8ball_pipelines.py::TestOutputDirectoryHandling::test_main_creates_provided_output_dir PASSED [ 45%]
tests/evaluation/test_compare_8ball_pipelines.py::TestErrorHandling::test_main_handles_missing_questions_file PASSED [ 45%]
tests/evaluation/test_compare_8ball_pipelines.py::TestErrorHandling::test_main_handles_model_evaluation_error PASSED [ 45%]
tests/evaluation/test_compare_8ball_pipelines.py::TestFileOutputFormat::test_main_outputs_correct_json_format PASSED [ 45%]
tests/evaluation/test_compare_8ball_pipelines.py::TestComparisonMetrics::test_main_calculates_comparison_metrics PASSED [ 46%]
tests/evaluation/test_compare_8ball_pipelines.py::TestComparisonMetrics::test_main_handles_missing_probabilities_for_ollama PASSED [ 46%]
tests/evaluation/test_evaluation_init.py::TestEvaluationInit::test_evaluation_module_import PASSED [ 46%]
tests/evaluation/test_evaluation_init.py::TestEvaluationInit::test_eightball_eval_import_alias PASSED [ 46%]
tests/evaluation/test_evaluation_init.py::TestEvaluationInit::test_evaluation_module_has_eightball_eval PASSED [ 46%]
tests/evaluation/test_long_ctx_eval.py::TestLongCtxEval::test_main_function PASSED [ 46%]
tests/evaluation/test_long_ctx_eval.py::TestLongCtxEval::test_main_function_no_exception PASSED [ 47%]
tests/evaluation/test_perf_mem_eval.py::TestHardwareInfo::test_hardware_info_creation PASSED [ 47%]
tests/evaluation/test_perf_mem_eval.py::TestHardwareInfo::test_hardware_info_default_export_path PASSED [ 47%]
tests/evaluation/test_perf_mem_eval.py::TestDetectHardware::test_detect_hardware_macos PASSED [ 47%]
tests/evaluation/test_perf_mem_eval.py::TestDetectHardware::test_detect_hardware_non_macos PASSED [ 47%]
tests/evaluation/test_perf_mem_eval.py::TestDetectHardware::test_detect_hardware_no_coremltools PASSED [ 47%]
tests/evaluation/test_perf_mem_eval.py::TestDetectHardware::test_detect_hardware_sysctl_failure PASSED [ 48%]
tests/evaluation/test_perf_mem_eval.py::TestStepAdapter::test_step_adapter_abstract_methods PASSED [ 48%]
tests/evaluation/test_perf_mem_eval.py::TestStepAdapter::test_step_adapter_subclass_implementation PASSED [ 48%]
tests/evaluation/test_perf_mem_eval.py::TestGreedyArgmax::test_greedy_argmax_single_max PASSED [ 48%]
tests/evaluation/test_perf_mem_eval.py::TestGreedyArgmax::test_greedy_argmax_multiple_same PASSED [ 48%]
tests/evaluation/test_perf_mem_eval.py::TestGreedyArgmax::test_greedy_argmax_single_element PASSED [ 48%]
tests/evaluation/test_perf_mem_eval.py::TestGreedyArgmax::test_greedy_argmax_negative_values PASSED [ 48%]
tests/evaluation/test_perf_mem_eval.py::TestGreedyArgmax::test_greedy_argmax_empty_array PASSED [ 49%]
tests/evaluation/test_perf_mem_eval.py::TestIsValidToolJSON::test_is_valid_tool_json_valid_simple PASSED [ 49%]
tests/evaluation/test_perf_mem_eval.py::TestIsValidToolJSON::test_is_valid_tool_json_valid_complex PASSED [ 49%]
tests/evaluation/test_perf_mem_eval.py::TestIsValidToolJSON::test_is_valid_tool_json_invalid_missing_braces PASSED [ 49%]
tests/evaluation/test_perf_mem_eval.py::TestIsValidToolJSON::test_is_valid_tool_json_empty_json PASSED [ 49%]
tests/evaluation/test_perf_mem_eval.py::TestIsValidToolJSON::test_is_valid_tool_json_missing_colon PASSED [ 49%]
tests/evaluation/test_perf_mem_eval.py::TestIsValidToolJSON::test_is_valid_tool_json_empty_string PASSED [ 50%]
tests/evaluation/test_perf_mem_eval.py::TestIsValidToolJSON::test_is_valid_tool_json_not_dict PASSED [ 50%]
tests/evaluation/test_perf_mem_eval.py::TestIsValidToolJSON::test_is_valid_tool_json_name_not_string PASSED [ 50%]
tests/evaluation/test_perf_mem_eval.py::TestIsValidToolJSON::test_is_valid_tool_json_arguments_not_dict PASSED [ 50%]
tests/evaluation/test_perf_mem_eval.py::TestRunCoreMLSpeed::test_run_coreml_speed_no_coremltools PASSED [ 50%]
tests/evaluation/test_perf_mem_eval.py::TestRunCoreMLSpeed::test_run_coreml_speed_standard_path PASSED [ 50%]
tests/evaluation/test_perf_mem_eval.py::TestRunCoreMLSpeed::test_run_coreml_speed_with_tokenizer PASSED [ 51%]
tests/evaluation/test_perf_mem_eval.py::TestRunCoreMLSpeed::test_run_coreml_speed_split_ttft PASSED [ 51%]
tests/evaluation/test_perf_mem_eval.py::TestRunCoreMLSpeed::test_run_coreml_speed_with_prompt_cache PASSED [ 51%]
tests/evaluation/test_perf_mem_eval.py::TestRunCoreMLSpeed::test_run_coreml_speed_with_speculative_decoder PASSED [ 51%]
tests/evaluation/test_perf_mem_eval.py::TestRunCoreMLSpeed::test_run_coreml_speed_with_kv_cache PASSED [ 51%]
tests/evaluation/test_perf_mem_eval.py::TestRunCoreMLSpeed::test_run_coreml_speed_with_batch_policy PASSED [ 51%]
tests/evaluation/test_perf_mem_eval.py::TestLoadTokenizedPrompts::test_load_tokenized_prompts_file_not_found PASSED [ 51%]
tests/evaluation/test_perf_mem_eval.py::TestLoadTokenizedPrompts::test_load_tokenized_prompts_jsonl_format PASSED [ 52%]
tests/evaluation/test_perf_mem_eval.py::TestLoadTokenizedPrompts::test_load_tokenized_prompts_with_input_dict PASSED [ 52%]
tests/evaluation/test_perf_mem_eval.py::TestLoadTokenizedPrompts::test_load_tokenized_prompts_return_texts PASSED [ 52%]
tests/evaluation/test_perf_mem_eval.py::TestLoadTokenizedPrompts::test_load_tokenized_prompts_max_samples PASSED [ 52%]
tests/evaluation/test_perf_mem_eval.py::TestLoadTokenizedPrompts::test_load_tokenized_prompts_optimized_tokenizer PASSED [ 52%]
tests/evaluation/test_perf_mem_eval.py::TestLoadTokenizedPrompts::test_load_tokenized_prompts_tokenizer_failure PASSED [ 52%]
tests/evaluation/test_perf_mem_eval.py::TestMainFunction::test_main_success PASSED [ 53%]
tests/evaluation/test_perf_mem_eval.py::TestMainFunction::test_main_missing_required_args PASSED [ 53%]
tests/evaluation/test_perf_mem_eval.py::TestPerfMemEvalIntegration::test_hardware_detection_integration PASSED [ 53%]
tests/evaluation/test_perf_mem_eval.py::TestPerfMemEvalIntegration::test_greedy_argmax_properties PASSED [ 53%]
tests/evaluation/test_perf_mem_eval.py::TestPerfMemEvalIntegration::test_json_validation_comprehensive PASSED [ 53%]
tests/evaluation/test_performance_benchmarks.py::TestModelRole::test_model_role_values PASSED [ 53%]
tests/evaluation/test_performance_benchmarks.py::TestModelRole::test_model_role_count PASSED [ 54%]
tests/evaluation/test_performance_benchmarks.py::TestPerformanceTargets::test_performance_targets_creation PASSED [ 54%]
tests/evaluation/test_performance_benchmarks.py::TestPerformanceTargetsConstants::test_performance_targets_all_roles PASSED [ 54%]
tests/evaluation/test_performance_benchmarks.py::TestPerformanceTargetsConstants::test_worker_targets PASSED [ 54%]
tests/evaluation/test_performance_benchmarks.py::TestPerformanceTargetsConstants::test_judge_targets PASSED [ 54%]
tests/evaluation/test_performance_benchmarks.py::TestPerformanceTargetsConstants::test_drafter_targets PASSED [ 54%]
tests/evaluation/test_performance_benchmarks.py::TestPerformanceMetrics::test_performance_metrics_creation PASSED [ 54%]
tests/evaluation/test_performance_benchmarks.py::TestPerformanceMetrics::test_performance_metrics_optional_fields PASSED [ 55%]
tests/evaluation/test_performance_benchmarks.py::TestPerformanceBenchmark::test_benchmark_initialization_worker PASSED [ 55%]
tests/evaluation/test_performance_benchmarks.py::TestPerformanceBenchmark::test_benchmark_initialization_judge PASSED [ 55%]
tests/evaluation/test_performance_benchmarks.py::TestPerformanceBenchmark::test_benchmark_initialization_drafter PASSED [ 55%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateLatency::test_evaluate_latency_empty_list PASSED [ 55%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateLatency::test_evaluate_latency_single_measurement PASSED [ 55%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateLatency::test_evaluate_latency_multiple_measurements PASSED [ 56%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateLatency::test_evaluate_latency_exceeds_target PASSED [ 56%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateLatency::test_evaluate_latency_worker_targets PASSED [ 56%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateThroughput::test_evaluate_throughput_passes PASSED [ 56%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateThroughput::test_evaluate_throughput_fails PASSED [ 56%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateThroughput::test_evaluate_throughput_worker PASSED [ 56%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateThroughput::test_evaluate_throughput_drafter PASSED [ 57%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateQuality::test_evaluate_quality_with_accuracy PASSED [ 57%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateQuality::test_evaluate_quality_with_confidence PASSED [ 57%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateQuality::test_evaluate_quality_with_both PASSED [ 57%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateQuality::test_evaluate_quality_fails PASSED [ 57%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateQuality::test_evaluate_quality_none_values PASSED [ 57%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateResources::test_evaluate_resources_passes PASSED [ 57%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateResources::test_evaluate_resources_fails PASSED [ 58%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateResources::test_evaluate_resources_worker PASSED [ 58%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateAll::test_evaluate_all_with_latencies PASSED [ 58%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateAll::test_evaluate_all_without_latencies PASSED [ 58%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateAll::test_evaluate_all_worker PASSED [ 58%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateAll::test_evaluate_all_drafter PASSED [ 58%]
tests/evaluation/test_performance_benchmarks.py::TestPerformanceBenchmarkIntegration::test_complete_benchmark_workflow PASSED [ 59%]
tests/evaluation/test_performance_benchmarks.py::TestPerformanceBenchmarkIntegration::test_benchmark_comparison_across_roles PASSED [ 59%]
tests/evaluation/test_performance_benchmarks.py::TestMeasureInferenceTime::test_measure_inference_time_basic PASSED [ 59%]
tests/evaluation/test_performance_benchmarks.py::TestMeasureInferenceTime::test_measure_inference_time_with_args PASSED [ 59%]
tests/evaluation/test_performance_benchmarks.py::TestMeasureInferenceTime::test_measure_inference_time_with_kwargs PASSED [ 59%]
tests/evaluation/test_performance_benchmarks.py::TestMeasureInferenceTime::test_measure_inference_time_returns_ms PASSED [ 59%]
tests/evaluation/test_performance_benchmarks.py::TestCalculateTokensPerSecond::test_calculate_tokens_per_second_basic PASSED [ 60%]
tests/evaluation/test_performance_benchmarks.py::TestCalculateTokensPerSecond::test_calculate_tokens_per_second_fast PASSED [ 60%]
tests/evaluation/test_performance_benchmarks.py::TestCalculateTokensPerSecond::test_calculate_tokens_per_second_slow PASSED [ 60%]
tests/evaluation/test_performance_benchmarks.py::TestCalculateTokensPerSecond::test_calculate_tokens_per_second_zero_latency PASSED [ 60%]
tests/evaluation/test_performance_benchmarks.py::TestCalculateTokensPerSecond::test_calculate_tokens_per_second_negative_latency PASSED [ 60%]
tests/evaluation/test_performance_benchmarks.py::TestCalculateTokensPerSecond::test_calculate_tokens_per_second_very_small_latency PASSED [ 60%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateAllEdgeCases::test_evaluate_all_with_zero_tokens_per_second PASSED [ 60%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateAllEdgeCases::test_evaluate_all_without_quality_metrics PASSED [ 61%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateAllEdgeCases::test_evaluate_all_overall_pass_calculation PASSED [ 61%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateAllEdgeCases::test_evaluate_all_overall_pass_fails PASSED [ 61%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateAllEdgeCases::test_evaluate_all_latency_percentile_calculation PASSED [ 61%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateAllEdgeCases::test_evaluate_all_latency_small_list PASSED [ 61%]
tests/evaluation/test_performance_benchmarks.py::TestLatencyEvaluationEdgeCases::test_evaluate_latency_empty_list PASSED [ 61%]
tests/evaluation/test_performance_benchmarks.py::TestLatencyEvaluationEdgeCases::test_evaluate_latency_single_value PASSED [ 62%]
tests/evaluation/test_performance_benchmarks.py::TestLatencyEvaluationEdgeCases::test_evaluate_latency_two_values PASSED [ 62%]
tests/evaluation/test_performance_benchmarks.py::TestLatencyEvaluationEdgeCases::test_evaluate_latency_exactly_at_threshold PASSED [ 62%]
tests/evaluation/test_performance_benchmarks.py::TestLatencyEvaluationEdgeCases::test_evaluate_latency_just_below_threshold PASSED [ 62%]
tests/evaluation/test_performance_benchmarks.py::TestLatencyEvaluationEdgeCases::test_evaluate_latency_just_above_threshold PASSED [ 62%]
tests/evaluation/test_performance_benchmarks.py::TestLatencyEvaluationEdgeCases::test_evaluate_latency_boundary_percentile_calculation PASSED [ 62%]
tests/evaluation/test_performance_benchmarks.py::TestLatencyEvaluationEdgeCases::test_evaluate_latency_large_list PASSED [ 62%]
tests/evaluation/test_performance_benchmarks.py::TestLatencyEvaluationEdgeCases::test_evaluate_latency_unsorted_list PASSED [ 63%]
tests/evaluation/test_performance_benchmarks.py::TestLatencyEvaluationEdgeCases::test_evaluate_latency_duplicate_values PASSED [ 63%]
tests/evaluation/test_performance_benchmarks.py::TestLatencyEvaluationEdgeCases::test_evaluate_latency_all_three_roles PASSED [ 63%]
tests/evaluation/test_performance_benchmarks.py::TestThroughputEvaluationEdgeCases::test_evaluate_throughput_zero_tokens_per_second PASSED [ 63%]
tests/evaluation/test_performance_benchmarks.py::TestThroughputEvaluationEdgeCases::test_evaluate_throughput_exactly_at_threshold PASSED [ 63%]
tests/evaluation/test_performance_benchmarks.py::TestThroughputEvaluationEdgeCases::test_evaluate_throughput_just_below_threshold PASSED [ 63%]
tests/evaluation/test_performance_benchmarks.py::TestThroughputEvaluationEdgeCases::test_evaluate_throughput_just_above_threshold PASSED [ 64%]
tests/evaluation/test_performance_benchmarks.py::TestThroughputEvaluationEdgeCases::test_evaluate_throughput_very_high_value PASSED [ 64%]
tests/evaluation/test_performance_benchmarks.py::TestThroughputEvaluationEdgeCases::test_evaluate_throughput_all_three_roles PASSED [ 64%]
tests/evaluation/test_performance_benchmarks.py::TestQualityEvaluationEdgeCases::test_evaluate_quality_no_metrics PASSED [ 64%]
tests/evaluation/test_performance_benchmarks.py::TestQualityEvaluationEdgeCases::test_evaluate_quality_only_accuracy PASSED [ 64%]
tests/evaluation/test_performance_benchmarks.py::TestQualityEvaluationEdgeCases::test_evaluate_quality_only_confidence PASSED [ 64%]
tests/evaluation/test_performance_benchmarks.py::TestQualityEvaluationEdgeCases::test_evaluate_quality_exactly_at_threshold PASSED [ 65%]
tests/evaluation/test_performance_benchmarks.py::TestQualityEvaluationEdgeCases::test_evaluate_quality_just_below_threshold PASSED [ 65%]
tests/evaluation/test_performance_benchmarks.py::TestQualityEvaluationEdgeCases::test_evaluate_quality_just_above_threshold PASSED [ 65%]
tests/evaluation/test_performance_benchmarks.py::TestQualityEvaluationEdgeCases::test_evaluate_quality_zero_accuracy PASSED [ 65%]
tests/evaluation/test_performance_benchmarks.py::TestQualityEvaluationEdgeCases::test_evaluate_quality_one_accuracy PASSED [ 65%]
tests/evaluation/test_performance_benchmarks.py::TestQualityEvaluationEdgeCases::test_evaluate_quality_all_three_roles PASSED [ 65%]
tests/evaluation/test_performance_benchmarks.py::TestResourceEvaluationEdgeCases::test_evaluate_resources_zero_memory PASSED [ 65%]
tests/evaluation/test_performance_benchmarks.py::TestResourceEvaluationEdgeCases::test_evaluate_resources_zero_cpu PASSED [ 66%]
tests/evaluation/test_performance_benchmarks.py::TestResourceEvaluationEdgeCases::test_evaluate_resources_exactly_at_threshold PASSED [ 66%]
tests/evaluation/test_performance_benchmarks.py::TestResourceEvaluationEdgeCases::test_evaluate_resources_just_below_threshold PASSED [ 66%]
tests/evaluation/test_performance_benchmarks.py::TestResourceEvaluationEdgeCases::test_evaluate_resources_just_above_threshold PASSED [ 66%]
tests/evaluation/test_performance_benchmarks.py::TestResourceEvaluationEdgeCases::test_evaluate_resources_very_high_values PASSED [ 66%]
tests/evaluation/test_performance_benchmarks.py::TestResourceEvaluationEdgeCases::test_evaluate_resources_all_three_roles PASSED [ 66%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateAllEdgeCasesExtended::test_evaluate_all_with_none_latency_ms PASSED [ 67%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateAllEdgeCasesExtended::test_evaluate_all_with_single_latency_measurement PASSED [ 67%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateAllEdgeCasesExtended::test_evaluate_all_overall_pass_with_none_quality PASSED [ 67%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateAllEdgeCasesExtended::test_evaluate_all_overall_pass_fails_on_memory PASSED [ 67%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateAllEdgeCasesExtended::test_evaluate_all_overall_pass_fails_on_cpu PASSED [ 67%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateAllEdgeCasesExtended::test_evaluate_all_overall_pass_fails_on_accuracy PASSED [ 67%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateAllEdgeCasesExtended::test_evaluate_all_overall_pass_fails_on_confidence PASSED [ 68%]
tests/evaluation/test_performance_benchmarks.py::TestEvaluateAllEdgeCasesExtended::test_evaluate_all_all_three_roles PASSED [ 68%]
tests/evaluation/test_performance_benchmarks.py::TestMeasureInferenceTimeEdgeCases::test_measure_inference_time_immediate_return PASSED [ 68%]
tests/evaluation/test_performance_benchmarks.py::TestMeasureInferenceTimeEdgeCases::test_measure_inference_time_with_args PASSED [ 68%]
tests/evaluation/test_performance_benchmarks.py::TestMeasureInferenceTimeEdgeCases::test_measure_inference_time_with_kwargs PASSED [ 68%]
tests/evaluation/test_performance_benchmarks.py::TestMeasureInferenceTimeEdgeCases::test_measure_inference_time_with_args_and_kwargs PASSED [ 68%]
tests/evaluation/test_performance_benchmarks.py::TestMeasureInferenceTimeEdgeCases::test_measure_inference_time_returns_none PASSED [ 68%]
tests/evaluation/test_performance_benchmarks.py::TestMeasureInferenceTimeEdgeCases::test_measure_inference_time_raises_exception PASSED [ 69%]
tests/evaluation/test_performance_benchmarks.py::TestCalculateTokensPerSecondEdgeCases::test_calculate_tokens_per_second_zero_latency PASSED [ 69%]
tests/evaluation/test_performance_benchmarks.py::TestCalculateTokensPerSecondEdgeCases::test_calculate_tokens_per_second_negative_latency PASSED [ 69%]
tests/evaluation/test_performance_benchmarks.py::TestCalculateTokensPerSecondEdgeCases::test_calculate_tokens_per_second_zero_tokens PASSED [ 69%]
tests/evaluation/test_performance_benchmarks.py::TestCalculateTokensPerSecondEdgeCases::test_calculate_tokens_per_second_normal_case PASSED [ 69%]
tests/evaluation/test_performance_benchmarks.py::TestCalculateTokensPerSecondEdgeCases::test_calculate_tokens_per_second_high_throughput PASSED [ 69%]
tests/evaluation/test_performance_benchmarks.py::TestCalculateTokensPerSecondEdgeCases::test_calculate_tokens_per_second_low_latency PASSED [ 70%]
tests/evaluation/test_performance_benchmarks.py::TestCalculateTokensPerSecondEdgeCases::test_calculate_tokens_per_second_fractional_latency PASSED [ 70%]
tests/evaluation/test_performance_benchmarks.py::TestCalculateTokensPerSecondEdgeCases::test_calculate_tokens_per_second_large_tokens PASSED [ 70%]
tests/evaluation/test_performance_benchmarks.py::TestPerformanceBenchmarkInitialization::test_performance_benchmark_all_roles PASSED [ 70%]
tests/evaluation/test_performance_benchmarks.py::TestPerformanceBenchmarkInitialization::test_performance_benchmark_targets_access PASSED [ 70%]
tests/evaluation/test_pipeline_preservation_eval.py::TestPipelinePreservationEvalMain::test_main_pytorch_only PASSED [ 70%]
tests/evaluation/test_pipeline_preservation_eval.py::TestPipelinePreservationEvalMain::test_main_pytorch_and_coreml_comparison PASSED [ 71%]
tests/evaluation/test_pipeline_preservation_eval.py::TestPipelinePreservationEvalMain::test_main_pytorch_and_ollama_comparison PASSED [ 71%]
tests/evaluation/test_pipeline_preservation_eval.py::TestPipelinePreservationEvalMain::test_main_all_backends_comparison PASSED [ 71%]
tests/evaluation/test_pipeline_preservation_eval.py::TestPipelinePreservationEvalMain::test_main_config_load_error PASSED [ 71%]
tests/evaluation/test_pipeline_preservation_eval.py::TestPipelinePreservationEvalMain::test_main_with_eval_questions_file PASSED [ 71%]
tests/evaluation/test_pipeline_preservation_eval.py::TestPipelinePreservationEvalMain::test_main_with_default_questions_from_module PASSED [ 71%]
tests/evaluation/test_pipeline_preservation_eval.py::TestPipelinePreservationEvalMain::test_main_fallback_to_default_questions PASSED [ 71%]
tests/evaluation/test_pipeline_preservation_eval.py::TestPipelinePreservationEvalMain::test_main_output_dir_creation PASSED [ 72%]
tests/evaluation/test_pipeline_preservation_eval.py::TestPipelinePreservationEvalMain::test_main_saves_pytorch_predictions PASSED [ 72%]
tests/evaluation/test_pipeline_preservation_eval.py::TestPipelinePreservationEvalMain::test_main_saves_comparison_metrics PASSED [ 72%]
tests/evaluation/test_pipeline_preservation_eval.py::TestPipelinePreservationEvalMain::test_main_handles_none_probabilities PASSED [ 72%]
tests/evaluation/test_pipeline_preservation_eval.py::TestPipelinePreservationEvalIntegration::test_pipeline_comparison_workflow PASSED [ 72%]
tests/evaluation/test_reasoning_eval.py::TestLoadModel::test_load_model_with_config PASSED [ 72%]
tests/evaluation/test_reasoning_eval.py::TestLoadModel::test_load_model_without_config PASSED [ 73%]
tests/evaluation/test_reasoning_eval.py::TestLoadModel::test_load_model_checkpoint_without_state_dict PASSED [ 73%]
tests/evaluation/test_reasoning_eval.py::TestGenerateText::test_generate_text_basic PASSED [ 73%]
tests/evaluation/test_reasoning_eval.py::TestGenerateText::test_generate_text_with_eos PASSED [ 73%]
tests/evaluation/test_reasoning_eval.py::TestGenerateText::test_generate_text_device_detection PASSED [ 73%]
tests/evaluation/test_reasoning_eval.py::TestGenerateText::test_generate_text_removes_prompt PASSED [ 73%]
tests/evaluation/test_reasoning_eval.py::TestGenerateText::test_generate_text_default_max_tokens PASSED [ 74%]
tests/evaluation/test_reasoning_eval.py::TestGetReasoningPrompts::test_get_reasoning_prompts_returns_list PASSED [ 74%]
tests/evaluation/test_reasoning_eval.py::TestGetReasoningPrompts::test_get_reasoning_prompts_structure PASSED [ 74%]
tests/evaluation/test_reasoning_eval.py::TestGetReasoningPrompts::test_get_reasoning_prompts_categories PASSED [ 74%]
tests/evaluation/test_reasoning_eval.py::TestGetReasoningPrompts::test_get_reasoning_prompts_non_empty PASSED [ 74%]
tests/evaluation/test_reasoning_eval.py::TestEvaluateReasoning::test_evaluate_reasoning_success PASSED [ 74%]
tests/evaluation/test_reasoning_eval.py::TestEvaluateReasoning::test_evaluate_reasoning_empty_responses PASSED [ 74%]
tests/evaluation/test_reasoning_eval.py::TestEvaluateReasoning::test_evaluate_reasoning_whitespace_only PASSED [ 75%]
tests/evaluation/test_reasoning_eval.py::TestEvaluateReasoning::test_evaluate_reasoning_category_stats PASSED [ 75%]
tests/evaluation/test_reasoning_eval.py::TestEvaluateReasoning::test_evaluate_reasoning_mixed_validity PASSED [ 75%]
tests/evaluation/test_reasoning_eval.py::TestEvaluateReasoning::test_evaluate_reasoning_empty_prompts PASSED [ 75%]
tests/evaluation/test_reasoning_eval.py::TestEvaluateReasoning::test_evaluate_reasoning_missing_category PASSED [ 75%]
tests/evaluation/test_reasoning_eval.py::TestEvaluateReasoning::test_evaluate_reasoning_results_structure PASSED [ 75%]
tests/evaluation/test_reasoning_eval.py::TestMainFunction::test_main_success PASSED [ 76%]
tests/evaluation/test_reasoning_eval.py::TestMainFunction::test_main_with_test_data PASSED [ 76%]
tests/evaluation/test_reasoning_eval.py::TestMainFunction::test_main_tokenizer_load_failure PASSED [ 76%]
tests/evaluation/test_reasoning_eval.py::TestMainFunction::test_main_output_file_creation PASSED [ 76%]
tests/evaluation/test_reasoning_eval.py::TestReasoningEvalIntegration::test_complete_reasoning_evaluation_workflow PASSED [ 76%]
tests/evaluation/test_reasoning_eval.py::TestReasoningEvalIntegration::test_load_model_checkpoint_not_found PASSED [ 76%]
tests/evaluation/test_reasoning_eval.py::TestReasoningEvalIntegration::test_get_reasoning_prompts_defaults PASSED [ 77%]
tests/evaluation/test_reasoning_eval.py::TestReasoningEvalIntegration::test_evaluate_reasoning_category_breakdown PASSED [ 77%]
tests/evaluation/test_reasoning_eval.py::TestReasoningEvalIntegration::test_evaluate_reasoning_progress_reporting PASSED [ 77%]
tests/evaluation/test_tool_use_eval.py::TestLoadModel::test_load_model_with_config PASSED [ 77%]
tests/evaluation/test_tool_use_eval.py::TestLoadModel::test_load_model_without_config PASSED [ 77%]
tests/evaluation/test_tool_use_eval.py::TestLoadModel::test_load_model_checkpoint_not_found PASSED [ 77%]
tests/evaluation/test_tool_use_eval.py::TestGenerateText::test_generate_text_basic PASSED [ 77%]
tests/evaluation/test_tool_use_eval.py::TestGenerateText::test_generate_text_with_eos PASSED [ 78%]
tests/evaluation/test_tool_use_eval.py::TestGenerateText::test_generate_text_temperature PASSED [ 78%]
tests/evaluation/test_tool_use_eval.py::TestGenerateText::test_generate_text_max_length PASSED [ 78%]
tests/evaluation/test_tool_use_eval.py::TestValidateJSON::test_validate_json_valid_simple PASSED [ 78%]
tests/evaluation/test_tool_use_eval.py::TestValidateJSON::test_validate_json_valid_complex PASSED [ 78%]
tests/evaluation/test_tool_use_eval.py::TestValidateJSON::test_validate_json_invalid_syntax PASSED [ 78%]
tests/evaluation/test_tool_use_eval.py::TestValidateJSON::test_validate_json_empty_string PASSED [ 79%]
tests/evaluation/test_tool_use_eval.py::TestValidateJSON::test_validate_json_whitespace_only PASSED [ 79%]
tests/evaluation/test_tool_use_eval.py::TestValidateJSON::test_validate_json_non_json_text PASSED [ 79%]
tests/evaluation/test_tool_use_eval.py::TestValidateJSON::test_validate_json_partial_json PASSED [ 79%]
tests/evaluation/test_tool_use_eval.py::TestExtractToolCall::test_extract_tool_call_valid_json PASSED [ 79%]
tests/evaluation/test_tool_use_eval.py::TestExtractToolCall::test_extract_tool_call_nested_structure PASSED [ 79%]
tests/evaluation/test_tool_use_eval.py::TestExtractToolCall::test_extract_tool_call_invalid_json PASSED [ 80%]
tests/evaluation/test_tool_use_eval.py::TestExtractToolCall::test_extract_tool_call_no_tool_call PASSED [ 80%]
tests/evaluation/test_tool_use_eval.py::TestExtractToolCall::test_extract_tool_call_empty_json PASSED [ 80%]
tests/evaluation/test_tool_use_eval.py::TestExtractToolCall::test_extract_tool_call_malformed_tool_call PASSED [ 80%]
tests/evaluation/test_tool_use_eval.py::TestExtractToolCall::test_extract_tool_call_multiple_tools PASSED [ 80%]
tests/evaluation/test_tool_use_eval.py::TestEvaluateToolUse::test_evaluate_tool_use_success PASSED [ 80%]
tests/evaluation/test_tool_use_eval.py::TestEvaluateToolUse::test_evaluate_tool_use_invalid_json PASSED [ 80%]
tests/evaluation/test_tool_use_eval.py::TestEvaluateToolUse::test_evaluate_tool_use_wrong_tool PASSED [ 81%]
tests/evaluation/test_tool_use_eval.py::TestEvaluateToolUse::test_evaluate_tool_use_model_load_failure PASSED [ 81%]
tests/evaluation/test_tool_use_eval.py::TestEvaluateToolUse::test_evaluate_tool_use_empty_test_cases PASSED [ 81%]
tests/evaluation/test_tool_use_eval.py::TestMainFunction::test_main_success PASSED [ 81%]
tests/evaluation/test_tool_use_eval.py::TestMainFunction::test_main_checkpoint_not_found PASSED [ 81%]
tests/evaluation/test_tool_use_eval.py::TestMainFunction::test_main_config_not_found PASSED [ 81%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_json_validation_edge_cases PASSED [ 82%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_tool_call_extraction_variations PASSED [ 82%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_complete_evaluation_workflow PASSED [ 82%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_evaluation_metrics_calculation PASSED [ 82%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_error_handling_robustness PASSED [ 82%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_load_model_checkpoint_without_state_dict PASSED [ 82%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_load_model_mock_path PASSED [ 82%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_generate_text_tokenizer_callable PASSED [ 83%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_generate_text_dict_tokenizer_output PASSED [ 83%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_generate_text_device_detection PASSED [ 83%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_generate_text_default_max_tokens PASSED [ 83%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_generate_text_max_length_parameter PASSED [ 83%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_generate_text_device_detection_fallback PASSED [ 83%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_generate_text_tokenizer_fallback_to_callable PASSED [ 84%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_generate_text_tokenizer_last_resort_dummy PASSED [ 84%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_generate_text_model_forward_fallback PASSED [ 84%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_generate_text_logits_tuple_output PASSED [ 84%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_generate_text_logits_shape_fallback PASSED [ 84%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_extract_tool_call_embedded_json PASSED [ 84%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_extract_tool_call_tool_call_field PASSED [ 85%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_extract_tool_call_no_name_field PASSED [ 85%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_extract_tool_call_incomplete_json PASSED [ 85%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_evaluate_tool_use_keyword_args PASSED [ 85%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_evaluate_tool_use_keyword_args_missing_params PASSED [ 85%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_evaluate_tool_use_positional_args_model_tokenizer PASSED [ 85%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_evaluate_tool_use_invalid_positional_args PASSED [ 85%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_evaluate_tool_use_json_repair_needed PASSED [ 86%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_evaluate_tool_use_args_comparison PASSED [ 86%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_evaluate_tool_use_wrong_args PASSED [ 86%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_evaluate_tool_use_checkpoint_path_tokenizer_failure PASSED [ 86%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_main_with_output_file PASSED [ 86%]
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_extract_tool_call_tool_calls_array PASSED [ 86%]
tests/evaluation/test_toy_binary_classifier.py::TestBinaryClassifierConstants::test_binary_answers_count PASSED [ 87%]
tests/evaluation/test_toy_binary_classifier.py::TestBinaryClassifierConstants::test_binary_token_range PASSED [ 87%]
tests/evaluation/test_toy_binary_classifier.py::TestBinaryClassifierConstants::test_id_to_binary_answer_mapping PASSED [ 87%]
tests/evaluation/test_toy_binary_classifier.py::TestBinaryClassifierConstants::test_binary_answer_to_id_mapping PASSED [ 87%]
tests/evaluation/test_toy_binary_classifier.py::TestBinaryClassifierConstants::test_mapping_consistency PASSED [ 87%]
tests/evaluation/test_toy_binary_classifier.py::TestBinaryClassifierConfig::test_binary_classifier_config_creation PASSED [ 87%]
tests/evaluation/test_toy_binary_classifier.py::TestBinaryClassifierConfig::test_binary_classifier_config_mappings PASSED [ 88%]
tests/evaluation/test_toy_binary_classifier.py::TestLoadBinaryEvalQuestions::test_load_binary_eval_questions_existing_file PASSED [ 88%]
tests/evaluation/test_toy_binary_classifier.py::TestLoadBinaryEvalQuestions::test_load_binary_eval_questions_nonexistent_file PASSED [ 88%]
tests/evaluation/test_toy_binary_classifier.py::TestLoadBinaryEvalQuestions::test_load_binary_eval_questions_default_questions_format PASSED [ 88%]
tests/evaluation/test_toy_binary_classifier.py::TestLoadBinaryEvalQuestions::test_load_binary_eval_questions_empty_questions PASSED [ 88%]
tests/evaluation/test_toy_binary_classifier.py::TestGetBinaryQuestions::test_get_binary_questions_custom_path PASSED [ 88%]
tests/evaluation/test_toy_binary_classifier.py::TestGetBinaryQuestions::test_get_binary_questions_creates_default PASSED [ 88%]
tests/evaluation/test_toy_binary_classifier.py::TestBinaryClassifierIntegration::test_complete_workflow PASSED [ 89%]
tests/evaluation/test_toy_binary_classifier.py::TestBinaryClassifierIntegration::test_answer_consistency PASSED [ 89%]
tests/evaluation/test_toy_contracts.py::TestHasNanOrZero::test_has_nan_or_zero_normal_values PASSED [ 89%]
tests/evaluation/test_toy_contracts.py::TestHasNanOrZero::test_has_nan_or_zero_contains_nan PASSED [ 89%]
tests/evaluation/test_toy_contracts.py::TestHasNanOrZero::test_has_nan_or_zero_all_zero PASSED [ 89%]
tests/evaluation/test_toy_contracts.py::TestHasNanOrZero::test_has_nan_or_zero_very_small_values PASSED [ 89%]
tests/evaluation/test_toy_contracts.py::TestHasNanOrZero::test_has_nan_or_zero_mixed_zero_and_nan PASSED [ 90%]
tests/evaluation/test_toy_contracts.py::TestHasNanOrZero::test_has_nan_or_zero_empty_list PASSED [ 90%]
tests/evaluation/test_toy_contracts.py::TestHasNanOrZero::test_has_nan_or_zero_single_value PASSED [ 90%]
tests/evaluation/test_toy_contracts.py::TestMicroF1::test_micro_f1_perfect_match PASSED [ 90%]
tests/evaluation/test_toy_contracts.py::TestMicroF1::test_micro_f1_no_matches PASSED [ 90%]
tests/evaluation/test_toy_contracts.py::TestMicroF1::test_micro_f1_partial_matches PASSED [ 90%]
tests/evaluation/test_toy_contracts.py::TestMicroF1::test_micro_f1_meaningful_tokens PASSED [ 91%]
tests/evaluation/test_toy_contracts.py::TestMicroF1::test_micro_f1_tool_tokens_present PASSED [ 91%]
tests/evaluation/test_toy_contracts.py::TestMicroF1::test_micro_f1_empty_samples PASSED [ 91%]
tests/evaluation/test_toy_contracts.py::TestMicroF1::test_micro_f1_missing_target PASSED [ 91%]
tests/evaluation/test_toy_contracts.py::TestMicroF1::test_micro_f1_missing_pred PASSED [ 91%]
tests/evaluation/test_toy_contracts.py::TestGreedyDecodeLogits::test_greedy_decode_logits_basic PASSED [ 91%]
tests/evaluation/test_toy_contracts.py::TestGreedyDecodeLogits::test_greedy_decode_logits_unknown_id PASSED [ 91%]
tests/evaluation/test_toy_contracts.py::TestGreedyDecodeLogits::test_greedy_decode_logits_multiple_max PASSED [ 92%]
tests/evaluation/test_toy_contracts.py::TestGreedyDecodeSequence::test_greedy_decode_sequence_2d PASSED [ 92%]
tests/evaluation/test_toy_contracts.py::TestGreedyDecodeSequence::test_greedy_decode_sequence_3d_single_batch PASSED [ 92%]
tests/evaluation/test_toy_contracts.py::TestGreedyDecodeSequence::test_greedy_decode_sequence_3d_multi_batch PASSED [ 92%]
tests/evaluation/test_toy_contracts.py::TestGreedyDecodeSequence::test_greedy_decode_sequence_max_steps PASSED [ 92%]
tests/evaluation/test_toy_contracts.py::TestGreedyDecodeSequence::test_greedy_decode_sequence_unknown_tokens PASSED [ 92%]
tests/evaluation/test_toy_contracts.py::TestLoadCoreMLModel::test_load_coreml_model_success PASSED [ 93%]
tests/evaluation/test_toy_contracts.py::TestLoadCoreMLModel::test_load_coreml_model_not_available PASSED [ 93%]
tests/evaluation/test_toy_contracts.py::TestMainFunction::test_main_success PASSED [ 93%]
tests/evaluation/test_toy_contracts.py::TestMainFunction::test_main_coreml_not_available PASSED [ 93%]
tests/evaluation/test_toy_contracts.py::TestMainFunction::test_main_numpy_not_available PASSED [ 93%]
tests/evaluation/test_toy_contracts.py::TestMainFunction::test_main_model_load_failure PASSED [ 93%]
tests/evaluation/test_toy_contracts.py::TestMainFunction::test_main_with_id2tok_file PASSED [ 94%]
tests/evaluation/test_toy_contracts.py::TestToyContractsIntegration::test_has_nan_or_zero_integration PASSED [ 94%]
tests/evaluation/test_toy_contracts.py::TestToyContractsIntegration::test_micro_f1_with_tool_spans PASSED [ 94%]
tests/evaluation/test_toy_contracts.py::TestToyContractsIntegration::test_greedy_decode_full_workflow PASSED [ 94%]
tests/evaluation/test_toy_eight_ball.py::TestEightBallConstants::test_eight_ball_answers_count PASSED [ 94%]
tests/evaluation/test_toy_eight_ball.py::TestEightBallConstants::test_eight_ball_token_range PASSED [ 94%]
tests/evaluation/test_toy_eight_ball.py::TestEightBallConstants::test_id_to_answer_mapping PASSED [ 94%]
tests/evaluation/test_toy_eight_ball.py::TestEightBallConstants::test_answer_to_id_mapping PASSED [ 95%]
tests/evaluation/test_toy_eight_ball.py::TestEightBallConstants::test_mapping_consistency PASSED [ 95%]
tests/evaluation/test_toy_eight_ball.py::TestEightBallConstants::test_all_answers_unique PASSED [ 95%]
tests/evaluation/test_toy_eight_ball.py::TestClassificationConfig::test_eight_ball_config_creation PASSED [ 95%]
tests/evaluation/test_toy_eight_ball.py::TestClassificationConfig::test_eight_ball_config_mappings PASSED [ 95%]
tests/evaluation/test_toy_eight_ball.py::TestClassificationConfig::test_classification_config_creation PASSED [ 95%]
tests/evaluation/test_toy_eight_ball.py::TestLoadEvalQuestions::test_load_eval_questions_existing_file PASSED [ 96%]
tests/evaluation/test_toy_eight_ball.py::TestLoadEvalQuestions::test_load_eval_questions_nonexistent_file PASSED [ 96%]
tests/evaluation/test_toy_eight_ball.py::TestLoadEvalQuestions::test_load_eval_questions_empty_questions PASSED [ 96%]
tests/evaluation/test_toy_eight_ball.py::TestLoadEvalQuestions::test_load_eval_questions_missing_questions_key PASSED [ 96%]
tests/evaluation/test_toy_eight_ball.py::TestGetEightBallQuestions::test_get_eight_ball_questions_default PASSED [ 96%]
tests/evaluation/test_toy_eight_ball.py::TestGetEightBallQuestions::test_get_eight_ball_questions_custom_path PASSED [ 96%]
tests/evaluation/test_toy_eight_ball.py::TestGetEightBallQuestions::test_get_eight_ball_questions_creates_default PASSED [ 97%]
tests/evaluation/test_toy_eight_ball.py::TestEightBallIntegration::test_complete_workflow PASSED [ 97%]
tests/evaluation/test_toy_eight_ball.py::TestEightBallIntegration::test_answer_consistency PASSED [ 97%]
tests/evaluation/test_toy_eight_ball.py::TestEightBallIntegration::test_token_ids_sequential PASSED [ 97%]
tests/evaluation/test_toy_ternary_classifier.py::TestTernaryClassifierConstants::test_ternary_answers_count PASSED [ 97%]
tests/evaluation/test_toy_ternary_classifier.py::TestTernaryClassifierConstants::test_ternary_token_range PASSED [ 97%]
tests/evaluation/test_toy_ternary_classifier.py::TestTernaryClassifierConstants::test_id_to_ternary_answer_mapping PASSED [ 97%]
tests/evaluation/test_toy_ternary_classifier.py::TestTernaryClassifierConstants::test_ternary_answer_to_id_mapping PASSED [ 98%]
tests/evaluation/test_toy_ternary_classifier.py::TestTernaryClassifierConstants::test_mapping_consistency PASSED [ 98%]
tests/evaluation/test_toy_ternary_classifier.py::TestTernaryClassifierConfig::test_ternary_classifier_config_creation PASSED [ 98%]
tests/evaluation/test_toy_ternary_classifier.py::TestTernaryClassifierConfig::test_ternary_classifier_config_mappings PASSED [ 98%]
tests/evaluation/test_toy_ternary_classifier.py::TestLoadTernaryEvalQuestions::test_load_ternary_eval_questions_existing_file PASSED [ 98%]
tests/evaluation/test_toy_ternary_classifier.py::TestLoadTernaryEvalQuestions::test_load_ternary_eval_questions_nonexistent_file PASSED [ 98%]
tests/evaluation/test_toy_ternary_classifier.py::TestLoadTernaryEvalQuestions::test_load_ternary_eval_questions_default_questions_format PASSED [ 99%]
tests/evaluation/test_toy_ternary_classifier.py::TestLoadTernaryEvalQuestions::test_load_ternary_eval_questions_empty_questions PASSED [ 99%]
tests/evaluation/test_toy_ternary_classifier.py::TestGetTernaryQuestions::test_get_ternary_questions_custom_path PASSED [ 99%]
tests/evaluation/test_toy_ternary_classifier.py::TestGetTernaryQuestions::test_get_ternary_questions_creates_default PASSED [ 99%]
tests/evaluation/test_toy_ternary_classifier.py::TestTernaryClassifierIntegration::test_complete_workflow PASSED [ 99%]
tests/evaluation/test_toy_ternary_classifier.py::TestTernaryClassifierIntegration::test_answer_consistency PASSED [ 99%]
tests/evaluation/test_toy_ternary_classifier.py::TestTernaryClassifierIntegration::test_uncertain_answer PASSED [100%]

=============================== warnings summary ===============================
tests/evaluation/test_8ball_eval.py::TestEvaluatePyTorchModel::test_evaluate_pytorch_model_tokenizer_failure
  /Users/darianrosebrook/Desktop/Projects/distill/training/safe_model_loading.py:183: UserWarning: Model 'dummy_model' not in revision map. Using 'main' branch. For production, pin to specific commit SHA. See get_model_revision()
    warnings.warn(

tests/evaluation/test_perf_mem_eval.py::TestRunCoreMLSpeed::test_run_coreml_speed_standard_path
tests/evaluation/test_perf_mem_eval.py::TestRunCoreMLSpeed::test_run_coreml_speed_with_tokenizer
tests/evaluation/test_perf_mem_eval.py::TestRunCoreMLSpeed::test_run_coreml_speed_split_ttft
tests/evaluation/test_perf_mem_eval.py::TestRunCoreMLSpeed::test_run_coreml_speed_with_prompt_cache
tests/evaluation/test_perf_mem_eval.py::TestRunCoreMLSpeed::test_run_coreml_speed_with_speculative_decoder
tests/evaluation/test_perf_mem_eval.py::TestRunCoreMLSpeed::test_run_coreml_speed_with_kv_cache
tests/evaluation/test_perf_mem_eval.py::TestRunCoreMLSpeed::test_run_coreml_speed_with_batch_policy
  /Users/darianrosebrook/Desktop/Projects/distill/venv/lib/python3.11/site-packages/numpy/lib/function_base.py:4655: RuntimeWarning: invalid value encountered in subtract
    diff_b_a = subtract(b, a)

tests/evaluation/test_perf_mem_eval.py::TestMainFunction::test_main_success
  /Users/darianrosebrook/Desktop/Projects/distill/training/safe_model_loading.py:84: UserWarning: Model 'tokenizer_path' not in revision map. Using 'main' branch. For production, pin to specific commit SHA. See get_model_revision()
    warnings.warn(

tests/evaluation/test_tool_use_eval.py::TestEvaluateToolUse::test_evaluate_tool_use_success
tests/evaluation/test_tool_use_eval.py::TestEvaluateToolUse::test_evaluate_tool_use_invalid_json
tests/evaluation/test_tool_use_eval.py::TestEvaluateToolUse::test_evaluate_tool_use_wrong_tool
tests/evaluation/test_tool_use_eval.py::TestEvaluateToolUse::test_evaluate_tool_use_empty_test_cases
tests/evaluation/test_tool_use_eval.py::TestMainFunction::test_main_success
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_complete_evaluation_workflow
tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_error_handling_robustness
  /Users/darianrosebrook/Desktop/Projects/distill/training/safe_model_loading.py:84: UserWarning: Model 'models/student/tokenizer' not in revision map. Using 'main' branch. For production, pin to specific commit SHA. See get_model_revision()
    warnings.warn(

tests/evaluation/test_tool_use_eval.py::TestEvaluateToolUse::test_evaluate_tool_use_success
  <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute

tests/evaluation/test_tool_use_eval.py::TestEvaluateToolUse::test_evaluate_tool_use_success
  <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute

tests/evaluation/test_tool_use_eval.py::TestToolUseEvalIntegration::test_main_with_output_file
  /Users/darianrosebrook/Desktop/Projects/distill/training/safe_model_loading.py:84: UserWarning: Model 'tokenizer' not in revision map. Using 'main' branch. For production, pin to specific commit SHA. See get_model_revision()
    warnings.warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
================================ tests coverage ================================
______________ coverage: platform darwin, python 3.11.13-final-0 _______________

Name                                              Stmts   Miss  Cover   Missing
-------------------------------------------------------------------------------
conversion/convert_coreml.py                        348    348     0%   13-762
conversion/export_onnx.py                            73     73     0%   4-158
conversion/export_pytorch.py                        153    153     0%   10-375
conversion/judge_export_coreml.py                    36     36     0%   5-97
conversion/judge_export_onnx.py                      43     43     0%   5-100
conversion/make_toy_block.py                         74     74     0%   11-135
conversion/make_toy_onnx.py                          35     35     0%   10-81
conversion/make_toy_torch.py                         55     55     0%   10-92
conversion/onnx_surgery.py                          116    116     0%   13-204
conversion/shape_validator.py                        60     60     0%   8-228
conversion/validators.py                              0      0   100%
evaluation/8ball_eval.py                            462     91    80%   22-23, 27-28, 90-92, 125, 155, 193-205, 243-244, 253-254, 262-263, 271-274, 322-323, 340-342, 360-367, 371, 378-386, 395-398, 403-406, 458, 464-465, 474-475, 492-495, 509-510, 595-597, 634-636, 773-777, 794, 799-802, 817-818, 826, 859-860, 863-864, 895-916, 930-933, 943
evaluation/__init__.py                                2      0   100%
evaluation/caws_eval.py                             402     56    86%   15-16, 85, 93-98, 119, 145, 216-221, 281, 285, 287, 289, 335, 355, 374, 391-392, 396-399, 411, 424-425, 670-677, 694, 699-701, 717-718, 730, 739, 743, 748, 752, 757, 779-781, 789-790, 796-800, 804
evaluation/claim_extraction_metrics.py               69      0   100%
evaluation/classification_eval.py                   401    103    74%   26-28, 33-34, 99, 103, 119, 129, 154, 159, 194-198, 212-215, 218, 233-234, 248-249, 259, 276-283, 287, 294-299, 304-309, 314-316, 369, 377-381, 395-398, 401, 403, 417-418, 428-435, 443-445, 450-452, 457-459, 518, 539-544, 567-568, 605-607, 681-683, 692-701, 715-716, 720-721, 723-727, 731-751, 755-775, 787
evaluation/compare_8ball_pipelines.py                81      3    96%   187, 189, 214
evaluation/eightball_eval.py                          6      6     0%   7-16
evaluation/long_ctx_eval.py                           4      1    75%   6
evaluation/perf_mem_eval.py                         507    194    62%   17-19, 27-29, 34-36, 218-222, 244-247, 258-262, 284, 294-302, 316-327, 387, 390-394, 410, 413-418, 464, 516-520, 524-525, 534-535, 540-544, 551-559, 570, 578, 590, 624-635, 638-641, 766, 770-771, 775-778, 782, 787-794, 802, 819-821, 826-846, 864-869, 878-881, 891-895, 904-942, 951-992, 997-1024, 1053-1084, 1097-1098, 1116, 1127-1133
evaluation/performance_benchmarks.py                 89      9    90%   322-350
evaluation/pipeline_preservation_eval.py            106      1    99%   269
evaluation/reasoning_eval.py                        107      7    93%   88, 237-241, 277
evaluation/tool_use_eval.py                         423    112    74%   47-53, 145-149, 155, 160-164, 187-193, 208-211, 227, 235, 262, 289, 377, 397-398, 410-412, 423-497, 506-508, 527-535, 555-561, 570, 591, 651, 683-685, 707-711, 749-753, 760-765, 798-801, 806-809, 814-817, 838-840, 852
evaluation/toy/__init__.py                            1      0   100%
evaluation/toy/binary_classifier.py                  23      0   100%
evaluation/toy/eight_ball.py                         30      0   100%
evaluation/toy/eight_ball_config.py                  22     22     0%   11-105
evaluation/toy/ternary_classifier.py                 23      0   100%
evaluation/toy_contracts.py                         151     22    85%   24-25, 31-32, 173-177, 199-201, 217-219, 228-231, 234-235, 301
models/student/architectures/gqa_transformer.py     242    200    17%   33-35, 39-40, 45-48, 51-53, 62-65, 68-81, 85-97, 104-129, 142-155, 158-201, 220-254, 259-270, 273-275, 284-288, 298-322, 326, 364-410, 432-455, 468-472
training/assertions.py                               87     87     0%   8-222
training/caws_context.py                            136    136     0%   14-378
training/caws_structure.py                           41     41     0%   10-140
training/claim_extraction.py                        111      9    92%   129, 144, 148, 191, 247, 249, 257, 263-264
training/config_validation.py                        83     83     0%   7-313
training/dataloader.py                                6      6     0%   1-9
training/dataset.py                                 313    294     6%   18-24, 30, 36-38, 82-103, 107-196, 200, 214-413, 426-626
training/dataset_answer_generation.py                60     60     0%   18-170
training/dataset_post_tool.py                        55     55     0%   18-162
training/dataset_tool_select.py                      56     56     0%   18-169
training/distill_answer_generation.py                94     94     0%   7-233
training/distill_intermediate.py                     24     24     0%   18-54
training/distill_kd.py                             1380   1380     0%   13-3258
training/distill_post_tool.py                        94     94     0%   7-229
training/distill_process.py                         192    192     0%   12-443
training/distill_tool_select.py                     143    143     0%   11-346
training/examples_priority3_integration.py          122    122     0%   16-397
training/export_student.py                           82     82     0%   10-166
training/extractors.py                              125    125     0%   13-288
training/feature_flags.py                           127    127     0%   7-345
training/halt_targets.py                             46     46     0%   12-209
training/input_validation.py                        252    252     0%   7-621
training/json_repair.py                              91     67    26%   16, 32-53, 71-76, 81, 103-115, 140-165, 188-199, 218-235
training/logging_utils.py                            58     58     0%   7-219
training/losses.py                                  366    366     0%   18-1185
training/make_toy_training.py                        68     68     0%   16-242
training/monitoring.py                              191    191     0%   7-527
training/performance_monitor.py                      91     91     0%   7-237
training/process_losses.py                          174    174     0%   10-431
training/prompt_templates.py                        121    121     0%   11-597
training/quality_scoring.py                         114    114     0%   10-297
training/quant_qat_int8.py                          279    279     0%   5-631
training/run_manifest.py                            123    123     0%   16-325
training/run_toy_distill.py                         256    256     0%   11-577
training/safe_checkpoint_loading.py                  40     26    35%   38, 61-117
training/safe_model_loading.py                       48     15    69%   36-41, 74, 124-144, 174
training/speed_metrics.py                            65     65     0%   10-187
training/teacher_cache.py                           102    102     0%   12-236
training/teacher_stub_toy.py                         99     99     0%   15-283
training/tokenizer_migration.py                      95     95     0%   12-291
training/tracing.py                                 143    143     0%   30-369
training/utils.py                                    27     27     0%   7-64
-------------------------------------------------------------------------------
TOTAL                                             10324   7808    24%
Coverage HTML written to dir htmlcov
Coverage JSON written to file coverage.json
======================= 635 passed, 19 warnings in 8.53s =======================
