{
  "prompt": "How does a neural network learn?",
  "teacher_text": "A neural network learns through a process of **trial and error, gradually adjusting its internal parameters** to minimize mistakes. Here's how it works step-by-step:\n\n## 1. **The Setup: A Network of Adjustable \"Knobs\"**\nA neural network consists of layers of interconnected nodes (neurons). Each connection has a **weight** (a number that scales the signal) and each neuron has a **bias** (a baseline activation). These weights and biases are the network's **learnable parameters**\u2014think of them as thousands of tiny knobs that can be tuned.\n\nInitially, all these weights are set to **random values**. The network knows nothing at the start.\n\n## 2. **Forward Propagation: Making a Guess**\nWhen you feed in data (e.g., a picture of a cat):\n- The input flows through the network layer by layer\n- Each connection multiplies the data by its weight\n- Neurons sum up their inputs, add bias, and apply an activation function\n- The final layer produces a **prediction** (e.g., \"90% cat, 10% dog\")\n\nBecause weights are random at first, the prediction is terrible.\n\n## 3. **Loss Calculation: Measuring the Error**\nThe network compares its prediction to the **true answer** (the label: \"this is a cat\") using a **loss function** (also called cost function). This is a mathematical formula that quantifies \"how wrong\" the prediction was.\n\n- If it predicted \"100% cat\" \u2192 Loss = 0 (perfect)\n- If it predicted \"10% cat\" \u2192 Loss = high number (big mistake)\n\nThe loss value is a **single number** representing total error.\n\n## 4. **Backward Propagation: Assigning Blame**\nThis is the core of learning. The network uses **backpropagation** to figure out:\n> *\"Which weights caused the error, and how much?\"*\n\nUsing calculus (specifically the **chain rule**), it calculates the **gradient** (partial derivative) of the loss with respect to *every single weight* in the network. The gradient tells you:\n- The **direction** to adjust each weight to increase the loss\n- So you go the **opposite direction** to decrease the loss\n\n## 5. **Gradient Descent: Turning the Knobs**\nNow the network updates all weights using an optimization algorithm (typically **gradient descent**):\n\n```\nNew Weight = Old Weight - (Learning Rate \u00d7 Gradient)\n```\n\n- **Learning Rate**: A small multiplier (e.g., 0.001) that controls step size. Too big = overshoot; too small = slow learning.\n- This happens for millions of weights simultaneously.\n\n## 6. **Repeat, Repeat, Repeat**\nThe network does this process over and over:\n- **Forward pass** (make guess)\n- **Calculate loss** (measure error)\n- **Backward pass** (calculate gradients)\n- **Update weights** (adjust knobs)\n\nEach full cycle through the training data is called an **epoch**. After thousands of epochs on thousands of examples, the weights",
  "teacher_logits": null,
  "metadata": {
    "temperature": 1.0,
    "top_p": 0.95,
    "max_tokens": 1024
  }
}