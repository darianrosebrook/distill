{
  "prompt": "Search for information about CoreML optimization and extract key techniques.",
  "teacher_text": "# CoreML Optimization: Key Techniques\n\n## 1. **Model Quantization**\nReducing numerical precision to shrink model size and improve performance:\n\n- **Float16**: Halves model size with minimal accuracy loss\n  ```python\n  model = ct.convert(model, compute_precision=ct.precision.FLOAT16)\n  ```\n\n- **Palettization**: Reduces weights to a color palette (8-bit, 6-bit, 4-bit, 2-bit)\n  ```python\n  from coremltools.optimize.coreml import palettize_weights\n  optimized_model = palettize_weights(model, nbits=4)\n  ```\n\n- **Linear Quantization**: Converts weights to 8-bit integers\n  ```python\n  from coremltools.optimize.coreml import linear_quantize_weights\n  optimized_model = linear_quantize_weights(model, config)\n  ```\n\n- **Lookup Table Quantization**: For specific layers using lookup tables\n\n## 2. **Weight Pruning**\nRemoves redundant connections to compress models:\n\n```python\nfrom coremltools.optimize.coreml import prune_weights\nconfig = ct.optimize.coreml.OptimizationConfig(\n    global_sparsity=0.5,  # 50% sparsity\n    weight_threshold=1024  # Only prune layers > 1024 weights\n)\npruned_model = prune_weights(model, config)\n```\n\n**Benefits**: 2-4x size reduction, faster inference on Neural Engine\n\n## 3. **Layer Fusion & Graph Optimizations**\nCoreML automatically fuses compatible layers:\n\n- **BatchNorm + Convolution** fusion\n- **Activation function fusion** (ReLU, sigmoid into preceding layers)\n- **Element-wise operation chaining**\n\n**Best Practice**: Use `ML Program` model type (modern format) instead of Neural Network for better optimizations:\n```python\nmodel = ct.convert(model, convert_to=\"mlprogram\")\n```\n\n## 4. **Compute Unit Strategy**\nExplicitly target hardware for optimal performance:\n\n```python\n# Default: lets CoreML decide\nconfig = mlmodel.configuration\nconfig.compute_units = ct.ComputeUnit.ALL  # CPU + GPU + Neural Engine\n\n# Or explicitly:\nconfig.compute_units = ct.ComputeUnit.CPU_ONLY\nconfig.compute_units = ct.ComputeUnit.CPU_AND_GPU\nconfig.compute_units = ct.ComputeUnit.CPU_AND_NE  # iOS 16+\n```\n\n**Guidelines**:\n- **Neural Engine**: Best for convolutions, LSTMs, large matrices\n- **GPU**: Good for custom layers, parallel operations\n- **CPU**: Fallback for unsupported ops, low latency\n\n## 5. **Input/Output Optimization**\n\n### Flexible Shapes\nEnable dynamic input sizes to avoid recompilation:\n```python\nimage_input = ct.ImageType(\n    shape=ct.Shape(shape=(1",
  "teacher_logits": null,
  "metadata": {
    "temperature": 1.0,
    "top_p": 0.95,
    "max_tokens": 1024
  }
}