"""End-to-end integration test for evaluation harness.

Tests the complete pipeline:
1. Run evaluation with fixtures
2. Verify fixture hit rate
3. Test sharding determinism (if model available)
4. Validate fingerprints
"""
from __future__ import annotations

import argparse
import subprocess
import sys
from pathlib import Path


def run_command(cmd: list[str], cwd: Path | None = None) -> tuple[int, str, str]:
    """Run command and return (returncode, stdout, stderr)."""
    result = subprocess.run(
        cmd,
        capture_output=True,
        text=True,
        cwd=cwd,
    )
    return result.returncode, result.stdout, result.stderr


def test_broker_smoke():
    """Test broker fixture hit rate."""
    print("\n[E2E] Testing broker fixture hit rate...")
    cmd = [sys.executable, "-m", "pytest", "tests/ci/test_broker_fixtures_hit_rate.py", "-v"]
    returncode, stdout, stderr = run_command(cmd)
    
    if returncode == 0:
        print("âœ… Broker smoke test passed")
        return True
    else:
        print(f"âŒ Broker smoke test failed:\n{stdout}\n{stderr}")
        return False


def test_sharding_determinism():
    """Test sharding determinism logic."""
    print("\n[E2E] Testing sharding determinism logic...")
    cmd = [sys.executable, "-m", "pytest", "tests/ci/test_sharding_determinism.py", "-v"]
    returncode, stdout, stderr = run_command(cmd)
    
    if returncode == 0:
        print("âœ… Sharding determinism tests passed")
        return True
    else:
        print(f"âŒ Sharding determinism tests failed:\n{stdout}\n{stderr}")
        return False


def test_eval_cli_help():
    """Test that CLI help works (validates imports)."""
    print("\n[E2E] Testing CLI imports and help...")
    cmd = [sys.executable, "-m", "eval.cli", "--help"]
    returncode, stdout, stderr = run_command(cmd)
    
    if returncode == 0 and "Tool-Integration Evaluation Harness" in stdout:
        print("âœ… CLI imports and help work")
        return True
    else:
        print(f"âŒ CLI help failed:\n{stdout}\n{stderr}")
        return False


def test_validation_script_help():
    """Test that validation script help works."""
    print("\n[E2E] Testing validation script imports and help...")
    cmd = [sys.executable, "-m", "scripts.validate_sharding_determinism", "--help"]
    returncode, stdout, stderr = run_command(cmd)
    
    if returncode == 0 and "validate sharding determinism" in stdout.lower():
        print("âœ… Validation script imports and help work")
        return True
    else:
        print(f"âŒ Validation script help failed:\n{stdout}\n{stderr}")
        return False


def test_fixture_loading():
    """Test that fixtures can be loaded."""
    print("\n[E2E] Testing fixture loading...")
    try:
        from eval.tool_broker.broker import ToolBroker
        
        fixtures_dir = Path("eval/tool_broker/fixtures")
        if not fixtures_dir.exists():
            print(f"âŒ Fixtures directory not found: {fixtures_dir}")
            return False
        
        broker = ToolBroker(str(fixtures_dir))
        
        # Test a lookup
        result = broker.call("web.search", {"q": "test query", "top_k": 3})
        
        if result.get("error") == "fixture_miss":
            print("âš ï¸  Fixture miss (expected for unknown query)")
        else:
            print("âœ… Fixtures loaded successfully")
        
        return True
    except Exception as e:
        print(f"âŒ Fixture loading failed: {e}")
        return False


def test_prompt_wrapper_loading():
    """Test that prompt wrappers can be loaded."""
    print("\n[E2E] Testing prompt wrapper loading...")
    try:
        from eval.runners.openai_http import OpenAIHTTPRunner
        
        wrapper_path = Path("eval/prompt_wrappers/minimal_system_user.j2")
        if not wrapper_path.exists():
            print(f"âš ï¸  Example wrapper not found: {wrapper_path}")
            return True  # Not a failure, just missing example
        
        # Try to create runner with wrapper (won't actually run without model)
        try:
            OpenAIHTTPRunner(
                model="test-model",
                prompt_wrapper=str(wrapper_path),
            )
            print("âœ… Prompt wrapper loading works")
            return True
        except Exception as e:
            # If it fails due to model, that's OK - we're just testing wrapper loading
            if "model" in str(e).lower() or "api" in str(e).lower():
                print("âœ… Prompt wrapper loading works (model error expected)")
                return True
            raise
    except Exception as e:
        print(f"âŒ Prompt wrapper loading failed: {e}")
        return False


def main() -> int:
    """Run end-to-end integration tests."""
    parser = argparse.ArgumentParser(description="End-to-end integration test for evaluation harness")
    parser.add_argument("--skip-broker", action="store_true", help="Skip broker smoke test")
    parser.add_argument("--skip-sharding", action="store_true", help="Skip sharding determinism test")
    parser.add_argument("--skip-fixtures", action="store_true", help="Skip fixture loading test")
    args = parser.parse_args()
    
    print("=" * 70)
    print("Evaluation Harness End-to-End Integration Test")
    print("=" * 70)
    
    results = []
    
    # Test 1: CLI imports
    results.append(("CLI Imports", test_eval_cli_help()))
    
    # Test 2: Validation script imports
    results.append(("Validation Script", test_validation_script_help()))
    
    # Test 3: Fixture loading
    if not args.skip_fixtures:
        results.append(("Fixture Loading", test_fixture_loading()))
    
    # Test 4: Prompt wrapper loading
    results.append(("Prompt Wrapper Loading", test_prompt_wrapper_loading()))
    
    # Test 5: Broker smoke test
    if not args.skip_broker:
        results.append(("Broker Smoke Test", test_broker_smoke()))
    
    # Test 6: Sharding determinism logic
    if not args.skip_sharding:
        results.append(("Sharding Determinism Logic", test_sharding_determinism()))
    
    # Summary
    print("\n" + "=" * 70)
    print("Test Summary")
    print("=" * 70)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for name, result in results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"{status}: {name}")
    
    print(f"\nTotal: {passed}/{total} tests passed")
    
    if passed == total:
        print("\nğŸ‰ All end-to-end integration tests passed!")
        return 0
    else:
        print(f"\nâš ï¸  {total - passed} test(s) failed")
        return 1


if __name__ == "__main__":
    sys.exit(main())

