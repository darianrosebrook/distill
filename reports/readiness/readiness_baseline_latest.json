{
  "timestamp": "2025-11-15T09:37:03.869422",
  "version": "1.0",
  "git": {
    "commit": "30d3fc9ebeb0853bbc245f0c0a8eca23c054aec0",
    "branch": "main",
    "dirty": false
  },
  "test_status": {
    "unit": {
      "total": 3145,
      "passed": 3009,
      "failed": 102,
      "skipped": 32,
      "errors": 2,
      "failures": [
        {
          "test": "tests/integration/test_training_pipeline.py::TestKDTrainingIntegration::test_kd_training_step",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/test_tokenizer_contract.py::test_special_token_ids_match_constants",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/test_tokenizer_contract.py::test_special_tokens_are_single_tokens",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/test_tokenizer_contract.py::test_round_trip_stability",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_dataset.py::TestKDDatasetBranchCoverage::test_kd_dataset_getitem_teacher_target_ids_padding_branch",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_dataset.py::TestKDDatasetBranchCoverage::test_kd_dataset_getitem_teacher_logits_dim2_padding_branch",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_json_repair.py::TestRepairJSON::test_repair_json_with_jsonrepair",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_json_repair.py::TestCheckJSONRepairNeeded::test_check_json_repair_needed_invalid_json",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_json_repair.py::TestCheckJSONRepairNeeded::test_check_json_repair_needed_repairable_json",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_json_repair.py::TestBatchCheckJSONRepair::test_batch_check_json_repair_mixed",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_json_repair.py::TestJSONRepairIntegration::test_repair_workflow",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_latent_curriculum.py::TestLatentCurriculum::test_curriculum_applies_latent_slots",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_latent_curriculum.py::TestLatentCurriculum::test_curriculum_creates_loss_mask",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_latent_curriculum.py::TestLatentCurriculum::test_loss_mask_masks_latent_spans",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_loss_mask_correctness.py::TestLossMaskCorrectness::test_loss_mask_excludes_latent_spans_from_supervision",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestMetricsCollector::test_metrics_collector_initialization",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestMetricsCollector::test_add_metric",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestMetricsCollector::test_add_metric_eviction",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestMetricsCollector::test_get_metrics_by_name",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestMetricsCollector::test_get_metrics_by_tags",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestMetricsCollector::test_get_latest_metric",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestMetricsCollector::test_get_metric_statistics",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestMetricsCollector::test_clear_metrics",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestMetricsCollector::test_thread_safety",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestHealthChecker::test_health_checker_initialization",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestHealthChecker::test_add_check",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestHealthChecker::test_run_check",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestHealthChecker::test_run_check_not_found",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestHealthChecker::test_run_all_checks",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestHealthChecker::test_get_component_status",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestHealthChecker::test_get_overall_health",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestSystemHealthChecks::test_system_health_checks_initialization",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestSystemHealthChecks::test_cpu_usage_check",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestSystemHealthChecks::test_memory_usage_check",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestSystemHealthChecks::test_gpu_check_no_gpu",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestSystemHealthChecks::test_gpu_check_with_gpu",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestSystemHealthChecks::test_disk_usage_check",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestSystemHealthChecks::test_network_connectivity_check",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestSystemHealthChecks::test_run_system_checks",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestTrainingMonitor::test_training_monitor_initialization",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestTrainingMonitor::test_start_monitoring",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestTrainingMonitor::test_stop_monitoring",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestTrainingMonitor::test_log_metric",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestTrainingMonitor::test_log_training_step",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestTrainingMonitor::test_log_validation_metrics",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestTrainingMonitor::test_get_monitoring_stats",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestTrainingMonitor::test_save_load_metrics",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestTrainingMonitor::test_alert_on_condition",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestConcurrencyAndPerformance::test_concurrent_metric_logging",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestConcurrencyAndPerformance::test_monitoring_performance",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring.py::TestSystemHealthChecksEdgeCases::test_check_gpu_memory_exception",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring_actual.py::TestMetricsCollectorActual::test_metrics_collector_initialization",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring_actual.py::TestSystemHealthChecks::test_check_gpu_memory_no_gpu",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring_actual.py::TestTrainingMonitorActual::test_get_status",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_monitoring_actual.py::TestInitializeMonitoring::test_initialize_monitoring",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_process_losses.py::TestJSONValidityLoss::test_json_validity_loss_valid_json",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_process_losses.py::TestToolSelectionLoss::test_tool_selection_loss_basic",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_process_losses.py::TestToolSelectionLossFromIDs::test_tool_selection_loss_from_ids_basic",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_process_losses.py::TestJSONValidityLossFromIDs::test_json_validity_loss_from_ids_basic",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_quality_scoring.py::TestHeuristicQualityScore::test_compute_heuristic_quality_score_word_count_50_to_500",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_quality_scoring.py::TestHeuristicQualityScore::test_compute_heuristic_quality_score_word_count_20_to_50",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_quality_scoring.py::TestHeuristicQualityScore::test_compute_heuristic_quality_score_ground_truth_full_overlap",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_quality_scoring.py::TestJSONValidityScore::test_compute_json_validity_score_mixed_valid_invalid",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_quant_qat_int8.py::TestMinMaxObserver::test_min_max_observer_forward_2d",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_quant_qat_int8.py::TestMinMaxObserver::test_min_max_observer_forward_multiple_observations",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_quant_qat_int8.py::TestMinMaxObserver::test_min_max_observer_1d_tensor",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_quant_qat_int8.py::TestFakeQuantize::test_fake_quantize_forward_training",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_quant_qat_int8.py::TestFakeQuantize::test_fake_quantize_forward_eval",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_quant_qat_int8.py::TestFakeQuantize::test_fake_quantize_signed_quantization",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_quant_qat_int8.py::TestFakeQuantize::test_fake_quantize_unsigned_quantization",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_quant_qat_int8.py::TestQuantizedLinear::test_quantized_linear_forward",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_quant_qat_int8.py::TestQuantizedLinear::test_quantized_linear_different_bits",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_quant_qat_int8.py::TestQuantizedAttention::test_quantized_attention_forward",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_quant_qat_int8.py::TestQuantizedAttention::test_quantized_attention_with_mask",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_quant_qat_int8.py::TestQuantizedAttention::test_quantized_attention_clamp_pre_softmax",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_quant_qat_int8.py::TestQuantizedAttention::test_quantized_attention_no_clamp",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_quant_qat_int8.py::TestLoadModelFromCheckpoint::test_load_model_from_checkpoint_success",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_quant_qat_int8.py::TestLoadModelFromCheckpoint::test_load_model_from_checkpoint_no_config",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_quant_qat_int8.py::TestQuantizationIntegration::test_observer_to_fake_quant_workflow",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_quant_qat_int8.py::TestQuantizationIntegration::test_quantized_linear_workflow",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_quant_qat_int8.py::TestQuantizationIntegration::test_quantized_model_forward",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_teacher_stub_toy.py::TestTeacherLogits::test_teacher_logits_hot_tokens",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_tokenizer_migration.py::TestVerifyTokenIDs::test_verify_token_ids_matching",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_tokenizer_migration.py::TestResizeModelEmbeddings::test_resize_model_embeddings_basic",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_tokenizer_migration.py::TestResizeModelEmbeddings::test_resize_model_embeddings_with_new_vocab_size",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_tokenizer_migration.py::TestResizeModelEmbeddings::test_resize_model_embeddings_tokenizer_len",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_tracing.py::TestTrainingTracerInit::test_tracer_init_basic",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_tracing.py::TestTrainingTracerInit::test_tracer_init_with_wandb",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_tracing.py::TestTrainingTracerLogMetrics::test_log_metrics_tensorboard",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_tracing.py::TestTrainingTracerLogMetrics::test_log_metrics_wandb",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_tracing.py::TestTrainingTracerLogHparams::test_log_hparams_tensorboard",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_tracing.py::TestTrainingTracerLogHparams::test_log_hparams_wandb",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_tracing.py::TestTrainingTracerLogModelGraph::test_log_model_graph_tensorboard",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_tracing.py::TestTrainingTracerLogModelGraph::test_log_model_graph_wandb",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_tracing.py::TestTrainingTracerLogText::test_log_text_tensorboard",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_tracing.py::TestTrainingTracerLogImage::test_log_image_tensorboard",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_tracing.py::TestTrainingTracerLogHistogram::test_log_histogram_tensorboard",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_tracing.py::TestTrainingTracerClose::test_close_tensorboard",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_tracing.py::TestTrainingTracerClose::test_close_wandb",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_tracing.py::TestCreateTracerFromConfig::test_create_tracer_from_config_wandb",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/unit/test_config_validation.py::TestConfigMerging::test_merge_configs_empty_list",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/unit/test_enumerated_shapes.py::TestSampleEnumeratedShape::test_custom_shape_probs",
          "error": "FAILED",
          "message": ""
        },
        {
          "test": "tests/training/test_teacher_cache.py::TestTeacherCacheIntegration::test_complete_cache_workflow",
          "error": "ERROR",
          "message": ""
        },
        {
          "test": "tests/training/test_teacher_cache.py::TestTeacherCacheIntegration::test_cache_with_version_upgrade",
          "error": "ERROR",
          "message": ""
        }
      ],
      "duration_seconds": 146.35
    },
    "integration": {
      "total": 0,
      "passed": 0,
      "failed": 0,
      "skipped": 0,
      "errors": 0,
      "failures": [],
      "duration_seconds": 0.0
    },
    "mutation": {
      "modules_tested": 0,
      "scores": {},
      "survivors": {},
      "timeouts": 0,
      "targets_met": 0,
      "targets_missed": []
    }
  },
  "coverage": {
    "overall": {
      "line_percent": 36.90685413005272,
      "branch_percent": 0.0,
      "lines_covered": 3360,
      "lines_total": 9104,
      "branches_covered": 0,
      "branches_total": 0
    },
    "by_module": {
      "conversion/convert_coreml.py": {
        "line_percent": 22.857142857142858,
        "branch_percent": 0.0,
        "lines_covered": 72,
        "lines_total": 315
      },
      "conversion/export_onnx.py": {
        "line_percent": 98.57142857142857,
        "branch_percent": 0.0,
        "lines_covered": 69,
        "lines_total": 70
      },
      "conversion/export_pytorch.py": {
        "line_percent": 55.921052631578945,
        "branch_percent": 0.0,
        "lines_covered": 85,
        "lines_total": 152
      },
      "conversion/judge_export_coreml.py": {
        "line_percent": 0.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 36
      },
      "conversion/judge_export_onnx.py": {
        "line_percent": 0.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 43
      },
      "conversion/make_toy_block.py": {
        "line_percent": 0.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 74
      },
      "conversion/make_toy_onnx.py": {
        "line_percent": 0.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 35
      },
      "conversion/make_toy_torch.py": {
        "line_percent": 0.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 55
      },
      "conversion/onnx_surgery.py": {
        "line_percent": 58.62068965517241,
        "branch_percent": 0.0,
        "lines_covered": 68,
        "lines_total": 116
      },
      "conversion/shape_validator.py": {
        "line_percent": 56.666666666666664,
        "branch_percent": 0.0,
        "lines_covered": 34,
        "lines_total": 60
      },
      "conversion/validators.py": {
        "line_percent": 100.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 0
      },
      "evaluation/8ball_eval.py": {
        "line_percent": 34.806629834254146,
        "branch_percent": 0.0,
        "lines_covered": 63,
        "lines_total": 181
      },
      "evaluation/__init__.py": {
        "line_percent": 100.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 0
      },
      "evaluation/caws_eval.py": {
        "line_percent": 47.337278106508876,
        "branch_percent": 0.0,
        "lines_covered": 80,
        "lines_total": 169
      },
      "evaluation/claim_extraction_metrics.py": {
        "line_percent": 61.19402985074627,
        "branch_percent": 0.0,
        "lines_covered": 41,
        "lines_total": 67
      },
      "evaluation/classification_eval.py": {
        "line_percent": 30.94170403587444,
        "branch_percent": 0.0,
        "lines_covered": 69,
        "lines_total": 223
      },
      "evaluation/compare_8ball_pipelines.py": {
        "line_percent": 0.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 78
      },
      "evaluation/long_ctx_eval.py": {
        "line_percent": 0.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 4
      },
      "evaluation/perf_mem_eval.py": {
        "line_percent": 36.13053613053613,
        "branch_percent": 0.0,
        "lines_covered": 155,
        "lines_total": 429
      },
      "evaluation/performance_benchmarks.py": {
        "line_percent": 0.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 89
      },
      "evaluation/pipeline_preservation_eval.py": {
        "line_percent": 0.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 100
      },
      "evaluation/reasoning_eval.py": {
        "line_percent": 0.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 106
      },
      "evaluation/tool_use_eval.py": {
        "line_percent": 38.07106598984772,
        "branch_percent": 0.0,
        "lines_covered": 75,
        "lines_total": 197
      },
      "evaluation/toy/__init__.py": {
        "line_percent": 0.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 1
      },
      "evaluation/toy/binary_classifier.py": {
        "line_percent": 0.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 24
      },
      "evaluation/toy/eight_ball.py": {
        "line_percent": 0.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 30
      },
      "evaluation/toy/eight_ball_config.py": {
        "line_percent": 0.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 22
      },
      "evaluation/toy/ternary_classifier.py": {
        "line_percent": 0.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 24
      },
      "evaluation/toy_contracts.py": {
        "line_percent": 0.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 151
      },
      "models/student/architectures/gqa_transformer.py": {
        "line_percent": 94.39655172413794,
        "branch_percent": 0.0,
        "lines_covered": 219,
        "lines_total": 232
      },
      "models/student/tokenizer/constants.py": {
        "line_percent": 100.0,
        "branch_percent": 0.0,
        "lines_covered": 7,
        "lines_total": 7
      },
      "models/teacher/teacher_client.py": {
        "line_percent": 57.407407407407405,
        "branch_percent": 0.0,
        "lines_covered": 248,
        "lines_total": 432
      },
      "training/assertions.py": {
        "line_percent": 29.761904761904763,
        "branch_percent": 0.0,
        "lines_covered": 25,
        "lines_total": 84
      },
      "training/caws_context.py": {
        "line_percent": 19.11764705882353,
        "branch_percent": 0.0,
        "lines_covered": 26,
        "lines_total": 136
      },
      "training/caws_structure.py": {
        "line_percent": 87.8048780487805,
        "branch_percent": 0.0,
        "lines_covered": 36,
        "lines_total": 41
      },
      "training/claim_extraction.py": {
        "line_percent": 68.47826086956522,
        "branch_percent": 0.0,
        "lines_covered": 63,
        "lines_total": 92
      },
      "training/config_validation.py": {
        "line_percent": 66.66666666666667,
        "branch_percent": 0.0,
        "lines_covered": 54,
        "lines_total": 81
      },
      "training/dataloader.py": {
        "line_percent": 0.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 6
      },
      "training/dataset.py": {
        "line_percent": 69.1699604743083,
        "branch_percent": 0.0,
        "lines_covered": 175,
        "lines_total": 253
      },
      "training/dataset_answer_generation.py": {
        "line_percent": 92.98245614035088,
        "branch_percent": 0.0,
        "lines_covered": 53,
        "lines_total": 57
      },
      "training/dataset_post_tool.py": {
        "line_percent": 90.9090909090909,
        "branch_percent": 0.0,
        "lines_covered": 50,
        "lines_total": 55
      },
      "training/dataset_tool_select.py": {
        "line_percent": 94.64285714285714,
        "branch_percent": 0.0,
        "lines_covered": 53,
        "lines_total": 56
      },
      "training/distill_answer_generation.py": {
        "line_percent": 0.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 93
      },
      "training/distill_intermediate.py": {
        "line_percent": 0.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 24
      },
      "training/distill_kd.py": {
        "line_percent": 27.897681854516385,
        "branch_percent": 0.0,
        "lines_covered": 349,
        "lines_total": 1251
      },
      "training/distill_post_tool.py": {
        "line_percent": 0.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 93
      },
      "training/distill_process.py": {
        "line_percent": 37.01657458563536,
        "branch_percent": 0.0,
        "lines_covered": 67,
        "lines_total": 181
      },
      "training/distill_tool_select.py": {
        "line_percent": 0.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 142
      },
      "training/examples_priority3_integration.py": {
        "line_percent": 0.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 122
      },
      "training/export_student.py": {
        "line_percent": 71.60493827160494,
        "branch_percent": 0.0,
        "lines_covered": 58,
        "lines_total": 81
      },
      "training/extractors.py": {
        "line_percent": 76.0,
        "branch_percent": 0.0,
        "lines_covered": 95,
        "lines_total": 125
      },
      "training/feature_flags.py": {
        "line_percent": 62.20472440944882,
        "branch_percent": 0.0,
        "lines_covered": 79,
        "lines_total": 127
      },
      "training/halt_targets.py": {
        "line_percent": 19.565217391304348,
        "branch_percent": 0.0,
        "lines_covered": 9,
        "lines_total": 46
      },
      "training/input_validation.py": {
        "line_percent": 53.01204819277108,
        "branch_percent": 0.0,
        "lines_covered": 88,
        "lines_total": 166
      },
      "training/json_repair.py": {
        "line_percent": 81.31868131868131,
        "branch_percent": 0.0,
        "lines_covered": 74,
        "lines_total": 91
      },
      "training/logging_utils.py": {
        "line_percent": 79.3103448275862,
        "branch_percent": 0.0,
        "lines_covered": 46,
        "lines_total": 58
      },
      "training/losses.py": {
        "line_percent": 73.40425531914893,
        "branch_percent": 0.0,
        "lines_covered": 207,
        "lines_total": 282
      },
      "training/make_toy_training.py": {
        "line_percent": 0.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 68
      },
      "training/monitoring.py": {
        "line_percent": 36.64921465968586,
        "branch_percent": 0.0,
        "lines_covered": 70,
        "lines_total": 191
      },
      "training/performance_monitor.py": {
        "line_percent": 0.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 91
      },
      "training/process_losses.py": {
        "line_percent": 50.0,
        "branch_percent": 0.0,
        "lines_covered": 87,
        "lines_total": 174
      },
      "training/prompt_templates.py": {
        "line_percent": 45.45454545454545,
        "branch_percent": 0.0,
        "lines_covered": 55,
        "lines_total": 121
      },
      "training/quality_scoring.py": {
        "line_percent": 85.21739130434783,
        "branch_percent": 0.0,
        "lines_covered": 98,
        "lines_total": 115
      },
      "training/quant_qat_int8.py": {
        "line_percent": 14.624505928853756,
        "branch_percent": 0.0,
        "lines_covered": 37,
        "lines_total": 253
      },
      "training/run_manifest.py": {
        "line_percent": 0.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 110
      },
      "training/run_toy_distill.py": {
        "line_percent": 0.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 185
      },
      "training/speed_metrics.py": {
        "line_percent": 89.23076923076923,
        "branch_percent": 0.0,
        "lines_covered": 58,
        "lines_total": 65
      },
      "training/teacher_cache.py": {
        "line_percent": 0.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 102
      },
      "training/teacher_stub_toy.py": {
        "line_percent": 0.0,
        "branch_percent": 0.0,
        "lines_covered": 0,
        "lines_total": 99
      },
      "training/tokenizer_migration.py": {
        "line_percent": 9.473684210526315,
        "branch_percent": 0.0,
        "lines_covered": 9,
        "lines_total": 95
      },
      "training/tracing.py": {
        "line_percent": 18.88111888111888,
        "branch_percent": 0.0,
        "lines_covered": 27,
        "lines_total": 143
      },
      "training/utils.py": {
        "line_percent": 100.0,
        "branch_percent": 0.0,
        "lines_covered": 27,
        "lines_total": 27
      }
    },
    "thresholds": {
      "line": 80.0,
      "branch": 90.0
    },
    "meets_thresholds": false,
    "critical_modules_below_threshold": [
      "conversion/convert_coreml.py",
      "conversion/export_onnx.py",
      "training/distill_kd.py",
      "training/losses.py"
    ]
  },
  "todos": {
    "total": 4505,
    "blocking": 0,
    "critical": 0,
    "high_confidence": 4502,
    "in_training_path": [
      {
        "file": "training/quant_qat_int8.py",
        "line": "279",
        "text": "For now, we'll use a simple approach: quantize the embedding weights",
        "confidence": 1.0
      },
      {
        "file": "training/quant_qat_int8.py",
        "line": "284",
        "text": "For now, we'll leave it as-is and document the trade-off",
        "confidence": 1.0
      },
      {
        "file": "training/run_toy_distill.py",
        "line": "178",
        "text": "For now, assume 8-ball datasets may have them",
        "confidence": 1.0
      },
      {
        "file": "training/run_toy_distill.py",
        "line": "313",
        "text": "For now, weight all positions equally but this could be improved",
        "confidence": 1.0
      },
      {
        "file": "training/examples_priority3_integration.py",
        "line": "183",
        "text": "Compute quality score for teacher output. This is a placeholder - in practice, you would use: - Human evaluation scores - Automated metrics (BLEU, ROUGE, etc.) - Model-based evaluation - Task-specific",
        "confidence": 1.0
      },
      {
        "file": "training/examples_priority3_integration.py",
        "line": "225",
        "text": "This is a simplified BLEU approximation without nltk",
        "confidence": 0.94
      },
      {
        "file": "training/examples_priority3_integration.py",
        "line": "232",
        "text": "Unigram precision (simplified BLEU-1)",
        "confidence": 1.0
      },
      {
        "file": "training/examples_priority3_integration.py",
        "line": "239",
        "text": "Brevity penalty (simplified)",
        "confidence": 1.0
      },
      {
        "file": "training/examples_priority3_integration.py",
        "line": "244",
        "text": "Simplified BLEU score (unigram precision with brevity penalty)",
        "confidence": 1.0
      },
      {
        "file": "training/losses.py",
        "line": "892",
        "text": "Combine penalties (sum with equal weights for now)",
        "confidence": 1.0
      },
      {
        "file": "training/distill_kd.py",
        "line": "1277",
        "text": "For now, check if it exists as a closure variable or use fallback",
        "confidence": 1.0
      },
      {
        "file": "training/claim_extraction.py",
        "line": "11",
        "text": "Claim extraction utilities for training dataset generation and loss computation. Provides simplified claim extraction for training purposes, focusing on: - Verifiable content detection - Atomic claim ",
        "confidence": 0.85
      },
      {
        "file": "training/claim_extraction.py",
        "line": "20",
        "text": "Simplified claim representation for training.",
        "confidence": 1.0
      },
      {
        "file": "training/claim_extraction.py",
        "line": "36",
        "text": "Simplified claim extractor for training purposes. Detects verifiable claims using heuristics: - Factual indicators (dates, quantities, code references) - Structured content (code blocks, lists, JSON) ",
        "confidence": 1.0
      },
      {
        "file": "training/claim_extraction.py",
        "line": "148",
        "text": "Check if sentence has factual structure (simplified).",
        "confidence": 1.0
      }
    ],
    "in_conversion_path": [
      {
        "file": "coreml/ane_checks.py",
        "line": "82",
        "text": "Check for placeholder marker",
        "confidence": 1.0
      },
      {
        "file": "coreml/probes/compare_probes.py",
        "line": "36",
        "text": "Run CoreML model inference. Assumes placeholder check already done in main().",
        "confidence": 1.0
      },
      {
        "file": "coreml/probes/compare_probes.py",
        "line": "60",
        "text": "Check for placeholder marker",
        "confidence": 1.0
      },
      {
        "file": "coreml/runtime/ane_monitor.py",
        "line": "127",
        "text": "For now, we'll use a simplified approach:",
        "confidence": 1.0
      },
      {
        "file": "coreml/runtime/ane_monitor.py",
        "line": "131",
        "text": "NOTE: This is an intentional fallback implementation, not a placeholder.",
        "confidence": 0.94
      },
      {
        "file": "coreml/runtime/ane_monitor.py",
        "line": "189",
        "text": "This is a simplified heuristic - production would use more sophisticated analysis",
        "confidence": 0.94
      },
      {
        "file": "coreml/runtime/constrained_decode.py",
        "line": "150",
        "text": "This FSM is deliberately simplified: we enforce key/value separators, brackets balance,",
        "confidence": 0.94
      },
      {
        "file": "coreml/runtime/speculative_decode.py",
        "line": "410",
        "text": "Simplified threshold-based acceptance (fallback)",
        "confidence": 1.0
      },
      {
        "file": "conversion/export_pytorch.py",
        "line": "108",
        "text": "For now, keep returning tensor directly - CoreML will name it",
        "confidence": 1.0
      },
      {
        "file": "conversion/convert_coreml.py",
        "line": "11",
        "text": "Convert ONNX \u2192 CoreML (mlprogram). Uses public MIL converter API. Usage: python -m conversion.convert_coreml \\ --backend onnx \\ --in onnx/toy.sanitized.onnx \\ --out coreml/artifacts/toy/model.mlpackag",
        "confidence": 1.0
      },
      {
        "file": "conversion/convert_coreml.py",
        "line": "80",
        "text": "Convert PyTorch model (TorchScript or ExportedProgram) to CoreML. Args: pytorch_model: TorchScript module or torch.export.ExportedProgram output_path: Output path for .mlpackage compute_units: \"all\", ",
        "confidence": 1.0
      },
      {
        "file": "conversion/convert_coreml.py",
        "line": "419",
        "text": "Convert ONNX model to CoreML using public MIL converter API. Args: onnx_path: Path to ONNX model file output_path: Output path for .mlpackage compute_units: \"all\", \"cpuandgpu\", or \"cpuonly\" target: De",
        "confidence": 1.0
      },
      {
        "file": "conversion/convert_coreml.py",
        "line": "473",
        "text": "ONNX is not a supported production path - always create placeholder",
        "confidence": 1.0
      },
      {
        "file": "conversion/convert_coreml.py",
        "line": "505",
        "text": "Create a placeholder .mlpackage for smoke tests.",
        "confidence": 1.0
      },
      {
        "file": "conversion/convert_coreml.py",
        "line": "509",
        "text": "Create .placeholder marker",
        "confidence": 1.0
      },
      {
        "file": "conversion/convert_coreml.py",
        "line": "543",
        "text": "Smoke test (creates placeholder on failure):",
        "confidence": 1.0
      },
      {
        "file": "conversion/make_toy_block.py",
        "line": "45",
        "text": "Simplified attention for parity testing (no GQA, no RoPE).",
        "confidence": 1.0
      },
      {
        "file": "conversion/judge_export_coreml.py",
        "line": "40",
        "text": "Convert Judge ONNX model to CoreML with INT8 quantization. Note: CoreMLTools does not natively support ONNX\u2192CoreML conversion. For production, convert ONNX\u2192PyTorch first, then use PyTorch\u2192CoreML. INT8",
        "confidence": 1.0
      }
    ],
    "placeholders": 29,
    "mock_data": 1
  },
  "readiness": {
    "status": "partial",
    "score": 53.6,
    "blockers": [
      {
        "category": "tests",
        "description": "102 unit test(s) failing",
        "severity": "high"
      },
      {
        "category": "coverage",
        "description": "Coverage below thresholds (line: 36.9%, branch: 0.0%)",
        "severity": "medium"
      },
      {
        "category": "coverage",
        "description": "Critical modules below threshold: conversion/convert_coreml.py, conversion/export_onnx.py, training/distill_kd.py",
        "severity": "high"
      },
      {
        "category": "todos",
        "description": "15 TODO(s) in training path",
        "severity": "high"
      },
      {
        "category": "todos",
        "description": "18 TODO(s) in conversion path",
        "severity": "high"
      }
    ],
    "warnings": [],
    "recommendations": [
      "Fix failing unit tests before proceeding",
      "Increase line coverage from 36.9% to 80%"
    ]
  },
  "metadata": {
    "python_version": "3.11.13",
    "platform": "Darwin",
    "assessment_duration_seconds": 437.541468
  }
}